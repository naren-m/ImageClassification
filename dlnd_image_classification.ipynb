{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:29, 5.76MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f108c315da0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    arr=x.astype('float32')\n",
    "    if arr.max() > 1.0:\n",
    "        arr/=255.0\n",
    "    return arr\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# Intro to TensofFlow, 13.One-Hot Encoding\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.zeros((len(x), 10))\n",
    "    \n",
    "    y[np.arange(len(x)), x] = 1\n",
    "    \n",
    "    return y\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html\n",
    "# http://stackoverflow.com/questions/29831489/numpy-1-hot-array\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    x = tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1],image_shape[2] ], name=\"x\")\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    y = tf.placeholder(tf.float32, shape= [None, n_classes], name=\"y\")\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\") \n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 (2, 2) (4, 4) (2, 2) (2, 2)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def maxpool2d(x, pool_ksize=(2,2), pool_strides = (2,2)):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "\n",
    "def conv2d(x, W, b, strides=(1,1)):\n",
    "    cnv_strides = [1, strides[0], strides[1], 1]\n",
    "    x = tf.nn.conv2d(x, W, strides=cnv_strides, padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    image_channels = x_tensor.shape.as_list()[-1]\n",
    "    conv_kernelsize_x = conv_ksize[0]\n",
    "    conv_kernelsize_y = conv_ksize[1]\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal((conv_kernelsize_x, \n",
    "                                         conv_kernelsize_y, \n",
    "                                         image_channels, \n",
    "                                         conv_num_outputs))) # (height, width, input_depth, output_depth)\n",
    "    b = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    x = conv2d(x_tensor, W, b, conv_strides)\n",
    "    \n",
    "    x = maxpool2d(x, pool_ksize, pool_strides)\n",
    "\n",
    "    return x \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.contrib.layers.flatten(x_tensor)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    tensor_size = x_tensor.shape.as_list()[-1]\n",
    "\n",
    "    shape = list((tensor_size, num_outputs) )\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal(shape))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    fc = tf.nn.relu(tf.add(tf.matmul(x_tensor, W), b))\n",
    "#     tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    depth = x_tensor.get_shape().as_list()[-1]\n",
    "    shape = (depth, num_outputs)\n",
    "   \n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.add(tf.matmul(x_tensor,weight), bias)\n",
    "#     return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "(?, 32, 32, 3)\n",
      "10 (3, 3) (1, 1) (6, 6) (1, 1)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "(?, 32, 32, 3)\n",
      "10 (3, 3) (1, 1) (6, 6) (1, 1)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    \n",
    "    x_tensor = x\n",
    "    \n",
    "    conv_num_outputs = 10\n",
    "\n",
    "    conv_ksize = (3, 3)\n",
    "    conv_strides = (1, 1)\n",
    "    pool_ksize = (6, 6)\n",
    "    pool_strides = (1, 1)\n",
    "    \n",
    "    model = conv2d_maxpool(x_tensor, \n",
    "                           conv_num_outputs, \n",
    "                           conv_ksize, \n",
    "                           conv_strides, \n",
    "                           pool_ksize, \n",
    "                           pool_strides)\n",
    "#     x_tensor = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "#     x_tensor = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    model = tf.nn.dropout(model, keep_prob=keep_prob)\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    model = flatten(model)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    model = fully_conn(model, 200)\n",
    "    model = fully_conn(model, 100)\n",
    "\n",
    "\n",
    "    \n",
    "    dropped_tensor = tf.nn.dropout(model, keep_prob=keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    op_tensor =  output(dropped_tensor, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return op_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch, writer=None, cnt =0): #\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    train_feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability}\n",
    "    summary = session.run(optimizer, feed_dict=train_feed_dict)\n",
    "    if writer is not None:\n",
    "        writer.add_summary(summary, cnt)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "#     \"\"\"\n",
    "#     Print information about loss and validation accuracy\n",
    "#     : session: Current TensorFlow session\n",
    "#     : feature_batch: Batch of Numpy image data\n",
    "#     : label_batch: Batch of Numpy label data\n",
    "#     : cost: TensorFlow cost function\n",
    "#     : accuracy: TensorFlow accuracy function\n",
    "#     \"\"\"\n",
    "#     # TODO: Implement Function\n",
    "#     pass\n",
    "\n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    import sys\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                            x: valid_features,\n",
    "                            y: valid_labels,\n",
    "                            keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                        loss,\n",
    "                        valid_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2195 Validation Accuracy: 0.207400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0535 Validation Accuracy: 0.261800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9912 Validation Accuracy: 0.298000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.8670 Validation Accuracy: 0.313400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.7733 Validation Accuracy: 0.341000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.7864 Validation Accuracy: 0.346400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.7150 Validation Accuracy: 0.368400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7037 Validation Accuracy: 0.392600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.6536 Validation Accuracy: 0.390800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.6320 Validation Accuracy: 0.388200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6266 Validation Accuracy: 0.413200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6224 Validation Accuracy: 0.425000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.5609 Validation Accuracy: 0.427800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.5183 Validation Accuracy: 0.421600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.4941 Validation Accuracy: 0.434400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.4671 Validation Accuracy: 0.439400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.4718 Validation Accuracy: 0.441000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4150 Validation Accuracy: 0.453200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.4442 Validation Accuracy: 0.451800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.4144 Validation Accuracy: 0.457600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.7744 Validation Accuracy: 0.176000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.1488 Validation Accuracy: 0.165000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.2013 Validation Accuracy: 0.167400\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.1349 Validation Accuracy: 0.194000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.0410 Validation Accuracy: 0.194200\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1379 Validation Accuracy: 0.207400\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.1192 Validation Accuracy: 0.211200\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.0717 Validation Accuracy: 0.209400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.1075 Validation Accuracy: 0.214800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.8846 Validation Accuracy: 0.232000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0769 Validation Accuracy: 0.262200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.0762 Validation Accuracy: 0.241800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.9619 Validation Accuracy: 0.241600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.9837 Validation Accuracy: 0.264800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.8775 Validation Accuracy: 0.255400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9967 Validation Accuracy: 0.264800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     2.0087 Validation Accuracy: 0.265400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.8869 Validation Accuracy: 0.270400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.8514 Validation Accuracy: 0.289400\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.7943 Validation Accuracy: 0.291200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9820 Validation Accuracy: 0.302000\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.8477 Validation Accuracy: 0.304600\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.8443 Validation Accuracy: 0.297400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.7735 Validation Accuracy: 0.318400\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.7432 Validation Accuracy: 0.318400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8641 Validation Accuracy: 0.336200\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.7870 Validation Accuracy: 0.349000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.6879 Validation Accuracy: 0.342000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.6458 Validation Accuracy: 0.340000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.6231 Validation Accuracy: 0.360000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8711 Validation Accuracy: 0.362200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.7498 Validation Accuracy: 0.375600\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.6443 Validation Accuracy: 0.359000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.5805 Validation Accuracy: 0.389800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.5460 Validation Accuracy: 0.386800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7171 Validation Accuracy: 0.402000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.6846 Validation Accuracy: 0.405200\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.5684 Validation Accuracy: 0.415800\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.4547 Validation Accuracy: 0.407000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.4852 Validation Accuracy: 0.409000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7243 Validation Accuracy: 0.403800\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.5958 Validation Accuracy: 0.425800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.5349 Validation Accuracy: 0.407800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.4369 Validation Accuracy: 0.411600\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.4587 Validation Accuracy: 0.428000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.7232 Validation Accuracy: 0.412600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.5264 Validation Accuracy: 0.411600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.4694 Validation Accuracy: 0.416200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.4279 Validation Accuracy: 0.441000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.5174 Validation Accuracy: 0.445800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.5838 Validation Accuracy: 0.442000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.5825 Validation Accuracy: 0.437000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.3757 Validation Accuracy: 0.458800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.3761 Validation Accuracy: 0.440000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.4410 Validation Accuracy: 0.453800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.5418 Validation Accuracy: 0.459400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.4011 Validation Accuracy: 0.450000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.3570 Validation Accuracy: 0.457200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.3638 Validation Accuracy: 0.462600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.4712 Validation Accuracy: 0.451400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.5503 Validation Accuracy: 0.459600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.4209 Validation Accuracy: 0.460000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.2545 Validation Accuracy: 0.462800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.3553 Validation Accuracy: 0.479200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.4458 Validation Accuracy: 0.453000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.5791 Validation Accuracy: 0.456600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.4638 Validation Accuracy: 0.469800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.3257 Validation Accuracy: 0.479000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.3350 Validation Accuracy: 0.485600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.4265 Validation Accuracy: 0.467400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.5685 Validation Accuracy: 0.470200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.3914 Validation Accuracy: 0.473200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.2198 Validation Accuracy: 0.494400\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.2330 Validation Accuracy: 0.482800\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.4248 Validation Accuracy: 0.479400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.5786 Validation Accuracy: 0.486200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.3905 Validation Accuracy: 0.487400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.2117 Validation Accuracy: 0.479200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.2442 Validation Accuracy: 0.502600\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.3184 Validation Accuracy: 0.502800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.5747 Validation Accuracy: 0.495800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.3962 Validation Accuracy: 0.488200\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.2537 Validation Accuracy: 0.481800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.1986 Validation Accuracy: 0.505800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.3276 Validation Accuracy: 0.497000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4777 Validation Accuracy: 0.496400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.3516 Validation Accuracy: 0.506200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.2565 Validation Accuracy: 0.485400\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.1989 Validation Accuracy: 0.509000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.2577 Validation Accuracy: 0.512600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.4772 Validation Accuracy: 0.508200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.3088 Validation Accuracy: 0.507800\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.2224 Validation Accuracy: 0.512000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.1663 Validation Accuracy: 0.519800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.2812 Validation Accuracy: 0.524400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.3612 Validation Accuracy: 0.512400\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.1778 Validation Accuracy: 0.511600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.1363 Validation Accuracy: 0.520800\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.1896 Validation Accuracy: 0.525400\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.1830 Validation Accuracy: 0.523200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.3835 Validation Accuracy: 0.515600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.2172 Validation Accuracy: 0.514200\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.0778 Validation Accuracy: 0.527400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.1162 Validation Accuracy: 0.533600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.1964 Validation Accuracy: 0.515800\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.3039 Validation Accuracy: 0.531200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.2971 Validation Accuracy: 0.523800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.0483 Validation Accuracy: 0.535600\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.1347 Validation Accuracy: 0.529000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.1489 Validation Accuracy: 0.518200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.2546 Validation Accuracy: 0.534000\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.1555 Validation Accuracy: 0.523800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.0138 Validation Accuracy: 0.520200\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.1602 Validation Accuracy: 0.517200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.1057 Validation Accuracy: 0.540200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.1581 Validation Accuracy: 0.537800\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.0520 Validation Accuracy: 0.531600\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.0069 Validation Accuracy: 0.535200\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.1429 Validation Accuracy: 0.534000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.0647 Validation Accuracy: 0.532600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.1413 Validation Accuracy: 0.541000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.0827 Validation Accuracy: 0.540000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.9304 Validation Accuracy: 0.550000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.0929 Validation Accuracy: 0.539200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.0213 Validation Accuracy: 0.540200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.0885 Validation Accuracy: 0.548400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.0123 Validation Accuracy: 0.535800\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.0190 Validation Accuracy: 0.543000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.0745 Validation Accuracy: 0.551000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.0226 Validation Accuracy: 0.544200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.0731 Validation Accuracy: 0.543200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.9651 Validation Accuracy: 0.552000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.9339 Validation Accuracy: 0.553000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.0602 Validation Accuracy: 0.527800\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.9951 Validation Accuracy: 0.538200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.1030 Validation Accuracy: 0.545200\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.0168 Validation Accuracy: 0.552800\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.9563 Validation Accuracy: 0.552200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.0106 Validation Accuracy: 0.550600\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.9232 Validation Accuracy: 0.548200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.544400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.9241 Validation Accuracy: 0.546200\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.9027 Validation Accuracy: 0.558400\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.9155 Validation Accuracy: 0.556600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.9305 Validation Accuracy: 0.549800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.0415 Validation Accuracy: 0.552200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.9564 Validation Accuracy: 0.552400\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.9182 Validation Accuracy: 0.552800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.9676 Validation Accuracy: 0.547200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.9160 Validation Accuracy: 0.553600\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.9503 Validation Accuracy: 0.548000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.0031 Validation Accuracy: 0.555200\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.8877 Validation Accuracy: 0.555800\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.9170 Validation Accuracy: 0.564400\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.8967 Validation Accuracy: 0.563800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.0084 Validation Accuracy: 0.566000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.8963 Validation Accuracy: 0.553600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.8403 Validation Accuracy: 0.547600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.9115 Validation Accuracy: 0.555600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.8912 Validation Accuracy: 0.560600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.9911 Validation Accuracy: 0.564600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.8748 Validation Accuracy: 0.557400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.8657 Validation Accuracy: 0.535000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.8833 Validation Accuracy: 0.562400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.9016 Validation Accuracy: 0.570800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.9714 Validation Accuracy: 0.553200\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.8997 Validation Accuracy: 0.563000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.8402 Validation Accuracy: 0.558800\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.8949 Validation Accuracy: 0.553000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.8373 Validation Accuracy: 0.561200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.9432 Validation Accuracy: 0.565800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.9138 Validation Accuracy: 0.561400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.8622 Validation Accuracy: 0.537400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.8577 Validation Accuracy: 0.565200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.7973 Validation Accuracy: 0.576000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.9436 Validation Accuracy: 0.574000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.8306 Validation Accuracy: 0.559200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.8343 Validation Accuracy: 0.560800\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.8226 Validation Accuracy: 0.572400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.8219 Validation Accuracy: 0.581000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.9294 Validation Accuracy: 0.573000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.8140 Validation Accuracy: 0.567800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.8228 Validation Accuracy: 0.572400\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.8596 Validation Accuracy: 0.563200\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.7502 Validation Accuracy: 0.573600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.8819 Validation Accuracy: 0.564600\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.8060 Validation Accuracy: 0.560200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.7624 Validation Accuracy: 0.576200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.8361 Validation Accuracy: 0.573200\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.7639 Validation Accuracy: 0.573600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.8304 Validation Accuracy: 0.576400\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.8016 Validation Accuracy: 0.567000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.7648 Validation Accuracy: 0.575400\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.8388 Validation Accuracy: 0.569400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.7304 Validation Accuracy: 0.568200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.7982 Validation Accuracy: 0.580800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.8033 Validation Accuracy: 0.564600\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.7382 Validation Accuracy: 0.568000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.7751 Validation Accuracy: 0.576800\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.7381 Validation Accuracy: 0.581200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.8310 Validation Accuracy: 0.579000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.8636 Validation Accuracy: 0.569800\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.7710 Validation Accuracy: 0.551800\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.7840 Validation Accuracy: 0.576800\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.7146 Validation Accuracy: 0.577600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.7851 Validation Accuracy: 0.584600\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.8555 Validation Accuracy: 0.577000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.7111 Validation Accuracy: 0.580400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.7228 Validation Accuracy: 0.573400\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.6523 Validation Accuracy: 0.587800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.7959 Validation Accuracy: 0.578600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.7666 Validation Accuracy: 0.577000\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.7093 Validation Accuracy: 0.573400\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.7210 Validation Accuracy: 0.577000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.6608 Validation Accuracy: 0.571800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.7639 Validation Accuracy: 0.588000\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.7853 Validation Accuracy: 0.578600\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.7125 Validation Accuracy: 0.581200\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.6808 Validation Accuracy: 0.579400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.6809 Validation Accuracy: 0.589800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.8281 Validation Accuracy: 0.579200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.7854 Validation Accuracy: 0.578200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.6786 Validation Accuracy: 0.586400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.7231 Validation Accuracy: 0.574800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.6478 Validation Accuracy: 0.588600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.7904 Validation Accuracy: 0.588400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.7166 Validation Accuracy: 0.580600\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.7258 Validation Accuracy: 0.577800\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.6484 Validation Accuracy: 0.578200\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.6517 Validation Accuracy: 0.594000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.7588 Validation Accuracy: 0.584800\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.7242 Validation Accuracy: 0.581600\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.6243 Validation Accuracy: 0.580800\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.6735 Validation Accuracy: 0.588000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.6535 Validation Accuracy: 0.588800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.6960 Validation Accuracy: 0.586600\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.6613 Validation Accuracy: 0.579800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.6223 Validation Accuracy: 0.577000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.6133 Validation Accuracy: 0.583800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.5937 Validation Accuracy: 0.596000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.7283 Validation Accuracy: 0.583800\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.6583 Validation Accuracy: 0.585200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.6741 Validation Accuracy: 0.584800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.6399 Validation Accuracy: 0.586800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.6204 Validation Accuracy: 0.595200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.7467 Validation Accuracy: 0.584000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.6594 Validation Accuracy: 0.585000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.6373 Validation Accuracy: 0.578000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.6013 Validation Accuracy: 0.590400\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.5927 Validation Accuracy: 0.597000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.7129 Validation Accuracy: 0.592600\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.6086 Validation Accuracy: 0.579400\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.6068 Validation Accuracy: 0.578600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.5786 Validation Accuracy: 0.594200\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.5730 Validation Accuracy: 0.596400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.6793 Validation Accuracy: 0.587000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.6497 Validation Accuracy: 0.584000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.5948 Validation Accuracy: 0.583600\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.5578 Validation Accuracy: 0.593400\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.5866 Validation Accuracy: 0.593800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.6740 Validation Accuracy: 0.587800\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.6114 Validation Accuracy: 0.584800\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.5967 Validation Accuracy: 0.583000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.5583 Validation Accuracy: 0.592600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.5339 Validation Accuracy: 0.588400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.6514 Validation Accuracy: 0.591000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.5206 Validation Accuracy: 0.580600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.6118 Validation Accuracy: 0.573800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.5594 Validation Accuracy: 0.596000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.5633 Validation Accuracy: 0.600200\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.6353 Validation Accuracy: 0.603000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.6017 Validation Accuracy: 0.583000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.5684 Validation Accuracy: 0.599200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.5577 Validation Accuracy: 0.592000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.5428 Validation Accuracy: 0.600800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.6450 Validation Accuracy: 0.590800\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.5626 Validation Accuracy: 0.590000\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.6181 Validation Accuracy: 0.577000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.5561 Validation Accuracy: 0.598800\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.4853 Validation Accuracy: 0.595200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.6377 Validation Accuracy: 0.599600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.5476 Validation Accuracy: 0.593600\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.5762 Validation Accuracy: 0.585800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.5001 Validation Accuracy: 0.598800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.4884 Validation Accuracy: 0.602800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.6460 Validation Accuracy: 0.603000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.5528 Validation Accuracy: 0.595400\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.5515 Validation Accuracy: 0.590400\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.5091 Validation Accuracy: 0.597600\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.4733 Validation Accuracy: 0.604000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.5659 Validation Accuracy: 0.603400\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.5536 Validation Accuracy: 0.586400\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.5478 Validation Accuracy: 0.588600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.5300 Validation Accuracy: 0.584400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.4375 Validation Accuracy: 0.606400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.5488 Validation Accuracy: 0.602000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.5862 Validation Accuracy: 0.582800\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.5234 Validation Accuracy: 0.588200\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.4812 Validation Accuracy: 0.591800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.4445 Validation Accuracy: 0.605600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.5385 Validation Accuracy: 0.602000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.5605 Validation Accuracy: 0.600000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.4983 Validation Accuracy: 0.590800\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.4979 Validation Accuracy: 0.598400\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.4686 Validation Accuracy: 0.597800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.5358 Validation Accuracy: 0.598200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.4925 Validation Accuracy: 0.595600\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.5076 Validation Accuracy: 0.592600\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.4952 Validation Accuracy: 0.606400\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.4300 Validation Accuracy: 0.601000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.5278 Validation Accuracy: 0.603200\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.4899 Validation Accuracy: 0.593400\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.5127 Validation Accuracy: 0.594400\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.4720 Validation Accuracy: 0.604000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.4187 Validation Accuracy: 0.603400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.5208 Validation Accuracy: 0.603400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.4701 Validation Accuracy: 0.583600\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.4707 Validation Accuracy: 0.605400\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.4632 Validation Accuracy: 0.608400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.4038 Validation Accuracy: 0.609000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.5235 Validation Accuracy: 0.602600\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.4782 Validation Accuracy: 0.601400\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.5107 Validation Accuracy: 0.600400\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.4570 Validation Accuracy: 0.608000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.3871 Validation Accuracy: 0.610600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.4936 Validation Accuracy: 0.606400\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.5058 Validation Accuracy: 0.601200\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.4480 Validation Accuracy: 0.594000\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.4280 Validation Accuracy: 0.607000\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.4012 Validation Accuracy: 0.610800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.4857 Validation Accuracy: 0.607200\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.5029 Validation Accuracy: 0.605200\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.4582 Validation Accuracy: 0.600600\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.4354 Validation Accuracy: 0.609000\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.3845 Validation Accuracy: 0.613600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.4665 Validation Accuracy: 0.609600\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.4381 Validation Accuracy: 0.590400\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.4754 Validation Accuracy: 0.590800\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.4192 Validation Accuracy: 0.612000\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.3805 Validation Accuracy: 0.614400\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.4774 Validation Accuracy: 0.605200\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.4154 Validation Accuracy: 0.597000\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.4491 Validation Accuracy: 0.598000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.4402 Validation Accuracy: 0.607200\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.3629 Validation Accuracy: 0.613000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.4790 Validation Accuracy: 0.611600\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.4199 Validation Accuracy: 0.594200\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.5036 Validation Accuracy: 0.599000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.4227 Validation Accuracy: 0.605200\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.3485 Validation Accuracy: 0.618000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.4708 Validation Accuracy: 0.607400\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     0.4105 Validation Accuracy: 0.598200\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.4720 Validation Accuracy: 0.603000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     0.4252 Validation Accuracy: 0.611000\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.3544 Validation Accuracy: 0.610400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.4731 Validation Accuracy: 0.611000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     0.4542 Validation Accuracy: 0.607200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.3905 Validation Accuracy: 0.601800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     0.4200 Validation Accuracy: 0.609400\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.3299 Validation Accuracy: 0.614000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.5084 Validation Accuracy: 0.604800\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.4183 Validation Accuracy: 0.604000\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.4159 Validation Accuracy: 0.604200\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     0.4091 Validation Accuracy: 0.613400\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.3163 Validation Accuracy: 0.615800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.4490 Validation Accuracy: 0.615200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.3977 Validation Accuracy: 0.602800\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.4110 Validation Accuracy: 0.603600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     0.4330 Validation Accuracy: 0.607800\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.3612 Validation Accuracy: 0.615800\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.4302 Validation Accuracy: 0.614200\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.3731 Validation Accuracy: 0.596800\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.4121 Validation Accuracy: 0.609200\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     0.4152 Validation Accuracy: 0.607200\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.2831 Validation Accuracy: 0.615800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.4140 Validation Accuracy: 0.611400\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.4191 Validation Accuracy: 0.605400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.3925 Validation Accuracy: 0.595200\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     0.3969 Validation Accuracy: 0.615600\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.3172 Validation Accuracy: 0.615400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.4675 Validation Accuracy: 0.607600\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.3712 Validation Accuracy: 0.602400\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.3973 Validation Accuracy: 0.613000\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     0.3749 Validation Accuracy: 0.611200\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.3146 Validation Accuracy: 0.617600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.4163 Validation Accuracy: 0.613200\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.3375 Validation Accuracy: 0.603800\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.3913 Validation Accuracy: 0.610800\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     0.3911 Validation Accuracy: 0.611400\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.2895 Validation Accuracy: 0.619400\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.4160 Validation Accuracy: 0.617000\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.3201 Validation Accuracy: 0.598800\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.3555 Validation Accuracy: 0.610200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.3429 Validation Accuracy: 0.613000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.3119 Validation Accuracy: 0.617000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.4223 Validation Accuracy: 0.613800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.3402 Validation Accuracy: 0.604800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.3694 Validation Accuracy: 0.608400\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.3525 Validation Accuracy: 0.614200\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.2702 Validation Accuracy: 0.613800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.3884 Validation Accuracy: 0.618000\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.3435 Validation Accuracy: 0.613800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.3993 Validation Accuracy: 0.605600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     0.3714 Validation Accuracy: 0.610400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.2590 Validation Accuracy: 0.620600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.4096 Validation Accuracy: 0.613400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.3235 Validation Accuracy: 0.610800\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.3225 Validation Accuracy: 0.609600\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.3587 Validation Accuracy: 0.610200\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.2371 Validation Accuracy: 0.609400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.3876 Validation Accuracy: 0.612800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.2752 Validation Accuracy: 0.610600\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.3347 Validation Accuracy: 0.613200\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.3282 Validation Accuracy: 0.617800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.2585 Validation Accuracy: 0.620400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.3816 Validation Accuracy: 0.619600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.2833 Validation Accuracy: 0.605000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.3424 Validation Accuracy: 0.611200\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.3282 Validation Accuracy: 0.618400\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.2348 Validation Accuracy: 0.608600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.3917 Validation Accuracy: 0.611800\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.2916 Validation Accuracy: 0.612600\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.3872 Validation Accuracy: 0.606000\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.3345 Validation Accuracy: 0.619000\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.1980 Validation Accuracy: 0.614800\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.3755 Validation Accuracy: 0.620600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.3096 Validation Accuracy: 0.616000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.3825 Validation Accuracy: 0.605200\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.3160 Validation Accuracy: 0.620600\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.2218 Validation Accuracy: 0.621600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.3751 Validation Accuracy: 0.616400\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.3131 Validation Accuracy: 0.609400\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.3343 Validation Accuracy: 0.616800\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.3263 Validation Accuracy: 0.618600\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.2203 Validation Accuracy: 0.619600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.3773 Validation Accuracy: 0.612600\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.3111 Validation Accuracy: 0.614200\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.3477 Validation Accuracy: 0.612600\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.3352 Validation Accuracy: 0.611800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.2274 Validation Accuracy: 0.612000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.3424 Validation Accuracy: 0.616800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.3301 Validation Accuracy: 0.614800\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.3285 Validation Accuracy: 0.615600\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.3145 Validation Accuracy: 0.619000\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.2341 Validation Accuracy: 0.618200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.3233 Validation Accuracy: 0.618200\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.2564 Validation Accuracy: 0.607000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.2973 Validation Accuracy: 0.621400\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.3143 Validation Accuracy: 0.613800\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.2058 Validation Accuracy: 0.615000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.3264 Validation Accuracy: 0.619400\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.2386 Validation Accuracy: 0.609200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.3398 Validation Accuracy: 0.611800\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.2958 Validation Accuracy: 0.618600\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.1795 Validation Accuracy: 0.619800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.3091 Validation Accuracy: 0.620400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.2730 Validation Accuracy: 0.612200\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.3419 Validation Accuracy: 0.617400\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.3098 Validation Accuracy: 0.614800\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.1809 Validation Accuracy: 0.620600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.3079 Validation Accuracy: 0.613600\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.2899 Validation Accuracy: 0.611000\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.3264 Validation Accuracy: 0.610000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.3311 Validation Accuracy: 0.616000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.1856 Validation Accuracy: 0.621400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.3299 Validation Accuracy: 0.616600\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.2809 Validation Accuracy: 0.616400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.3055 Validation Accuracy: 0.618800\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.3212 Validation Accuracy: 0.611800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.1971 Validation Accuracy: 0.620400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.3117 Validation Accuracy: 0.618000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.2708 Validation Accuracy: 0.608200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.3203 Validation Accuracy: 0.617000\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.2837 Validation Accuracy: 0.616400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.1846 Validation Accuracy: 0.620800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.3044 Validation Accuracy: 0.617400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.2742 Validation Accuracy: 0.616000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.3035 Validation Accuracy: 0.620000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.2869 Validation Accuracy: 0.619200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.1716 Validation Accuracy: 0.623600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.3346 Validation Accuracy: 0.617600\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.2527 Validation Accuracy: 0.602800\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.3308 Validation Accuracy: 0.608200\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.3223 Validation Accuracy: 0.619600\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.1512 Validation Accuracy: 0.615600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.3145 Validation Accuracy: 0.617600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.2654 Validation Accuracy: 0.608600\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.3114 Validation Accuracy: 0.614400\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.2767 Validation Accuracy: 0.621200\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.1844 Validation Accuracy: 0.615000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.3202 Validation Accuracy: 0.615400\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.2557 Validation Accuracy: 0.607800\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.3118 Validation Accuracy: 0.625800\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.2858 Validation Accuracy: 0.619200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.1745 Validation Accuracy: 0.622000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.3074 Validation Accuracy: 0.618200\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.2569 Validation Accuracy: 0.611400\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.3107 Validation Accuracy: 0.615000\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.2859 Validation Accuracy: 0.625000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.1612 Validation Accuracy: 0.619800\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     0.3105 Validation Accuracy: 0.613800\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     0.2573 Validation Accuracy: 0.618400\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     0.2717 Validation Accuracy: 0.625200\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     0.2807 Validation Accuracy: 0.615600\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     0.1707 Validation Accuracy: 0.621600\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.2931 Validation Accuracy: 0.618800\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     0.2566 Validation Accuracy: 0.620400\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     0.2638 Validation Accuracy: 0.618000\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     0.2639 Validation Accuracy: 0.618000\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     0.1737 Validation Accuracy: 0.618200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.2870 Validation Accuracy: 0.615000\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     0.2527 Validation Accuracy: 0.610400\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     0.2879 Validation Accuracy: 0.624000\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     0.2743 Validation Accuracy: 0.616000\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     0.1677 Validation Accuracy: 0.618000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.2916 Validation Accuracy: 0.615400\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     0.2226 Validation Accuracy: 0.612400\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     0.2772 Validation Accuracy: 0.618600\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     0.2957 Validation Accuracy: 0.616400\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     0.1593 Validation Accuracy: 0.617600\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     0.3280 Validation Accuracy: 0.611000\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     0.2340 Validation Accuracy: 0.612000\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     0.3005 Validation Accuracy: 0.611200\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     0.2492 Validation Accuracy: 0.616200\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     0.1568 Validation Accuracy: 0.623200\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.2974 Validation Accuracy: 0.617000\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     0.2167 Validation Accuracy: 0.611200\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     0.2905 Validation Accuracy: 0.618200\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     0.2530 Validation Accuracy: 0.617000\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     0.1641 Validation Accuracy: 0.615600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.3004 Validation Accuracy: 0.609800\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     0.2397 Validation Accuracy: 0.612000\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     0.2486 Validation Accuracy: 0.620200\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     0.2605 Validation Accuracy: 0.619600\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     0.1223 Validation Accuracy: 0.620400\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.3125 Validation Accuracy: 0.621800\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     0.2266 Validation Accuracy: 0.612400\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     0.2645 Validation Accuracy: 0.617800\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     0.2909 Validation Accuracy: 0.616200\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     0.1333 Validation Accuracy: 0.623800\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.2857 Validation Accuracy: 0.618000\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     0.2143 Validation Accuracy: 0.616000\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     0.2474 Validation Accuracy: 0.620400\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     0.2589 Validation Accuracy: 0.616000\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     0.1384 Validation Accuracy: 0.616400\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.2736 Validation Accuracy: 0.614400\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     0.2005 Validation Accuracy: 0.615400\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     0.2544 Validation Accuracy: 0.621800\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     0.2577 Validation Accuracy: 0.617000\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     0.1297 Validation Accuracy: 0.614000\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.2603 Validation Accuracy: 0.618600\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     0.2039 Validation Accuracy: 0.612400\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     0.2502 Validation Accuracy: 0.620000\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     0.2449 Validation Accuracy: 0.618800\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     0.1274 Validation Accuracy: 0.617400\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.2849 Validation Accuracy: 0.613200\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     0.2238 Validation Accuracy: 0.617200\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     0.2544 Validation Accuracy: 0.612400\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     0.2468 Validation Accuracy: 0.612400\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     0.1342 Validation Accuracy: 0.610600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.2618 Validation Accuracy: 0.615800\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     0.2309 Validation Accuracy: 0.608800\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     0.2766 Validation Accuracy: 0.615800\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     0.2399 Validation Accuracy: 0.618400\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     0.0987 Validation Accuracy: 0.623400\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.2783 Validation Accuracy: 0.614600\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     0.2295 Validation Accuracy: 0.615800\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     0.2189 Validation Accuracy: 0.614600\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     0.2272 Validation Accuracy: 0.618200\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     0.1026 Validation Accuracy: 0.619800\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.2531 Validation Accuracy: 0.616400\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     0.2196 Validation Accuracy: 0.610000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     0.2160 Validation Accuracy: 0.617600\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     0.2505 Validation Accuracy: 0.619800\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     0.1059 Validation Accuracy: 0.618200\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.2775 Validation Accuracy: 0.615200\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     0.2141 Validation Accuracy: 0.615400\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     0.2328 Validation Accuracy: 0.621600\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     0.2545 Validation Accuracy: 0.616200\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     0.1115 Validation Accuracy: 0.616200\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.2478 Validation Accuracy: 0.613600\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     0.2271 Validation Accuracy: 0.619400\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     0.2229 Validation Accuracy: 0.620600\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     0.2523 Validation Accuracy: 0.607800\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     0.1056 Validation Accuracy: 0.619400\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.2506 Validation Accuracy: 0.613200\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     0.1943 Validation Accuracy: 0.615400\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     0.2207 Validation Accuracy: 0.621800\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     0.2540 Validation Accuracy: 0.618600\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     0.1020 Validation Accuracy: 0.614800\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.2404 Validation Accuracy: 0.615200\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     0.2040 Validation Accuracy: 0.606600\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     0.1986 Validation Accuracy: 0.624400\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     0.2399 Validation Accuracy: 0.618800\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     0.1034 Validation Accuracy: 0.614000\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.2334 Validation Accuracy: 0.618800\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     0.2271 Validation Accuracy: 0.616000\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     0.2025 Validation Accuracy: 0.620200\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     0.2218 Validation Accuracy: 0.612000\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     0.1079 Validation Accuracy: 0.615600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.2424 Validation Accuracy: 0.619600\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     0.2169 Validation Accuracy: 0.610000\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     0.2158 Validation Accuracy: 0.614400\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     0.2376 Validation Accuracy: 0.614400\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     0.0977 Validation Accuracy: 0.614400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.2332 Validation Accuracy: 0.622200\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     0.2093 Validation Accuracy: 0.620600\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     0.2121 Validation Accuracy: 0.622400\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     0.2148 Validation Accuracy: 0.624600\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     0.0903 Validation Accuracy: 0.615400\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.2189 Validation Accuracy: 0.610800\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     0.2094 Validation Accuracy: 0.614800\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     0.2222 Validation Accuracy: 0.612600\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     0.2204 Validation Accuracy: 0.614600\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     0.0756 Validation Accuracy: 0.624000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.2588 Validation Accuracy: 0.621200\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     0.2032 Validation Accuracy: 0.619000\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     0.2212 Validation Accuracy: 0.619600\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     0.2057 Validation Accuracy: 0.620800\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     0.0720 Validation Accuracy: 0.619200\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.2316 Validation Accuracy: 0.615600\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     0.1743 Validation Accuracy: 0.612000\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     0.2227 Validation Accuracy: 0.615400\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     0.2127 Validation Accuracy: 0.611000\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     0.0911 Validation Accuracy: 0.619400\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.2339 Validation Accuracy: 0.614600\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     0.1776 Validation Accuracy: 0.620000\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     0.2005 Validation Accuracy: 0.617800\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     0.2350 Validation Accuracy: 0.620000\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     0.0948 Validation Accuracy: 0.619600\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.2174 Validation Accuracy: 0.614400\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     0.1858 Validation Accuracy: 0.621000\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     0.1894 Validation Accuracy: 0.623200\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     0.2181 Validation Accuracy: 0.619600\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     0.0757 Validation Accuracy: 0.622800\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.2084 Validation Accuracy: 0.618200\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     0.1833 Validation Accuracy: 0.620400\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     0.2061 Validation Accuracy: 0.613400\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     0.2283 Validation Accuracy: 0.618400\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     0.0799 Validation Accuracy: 0.620200\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.2318 Validation Accuracy: 0.620800\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     0.1772 Validation Accuracy: 0.616800\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     0.1998 Validation Accuracy: 0.618600\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     0.2088 Validation Accuracy: 0.615200\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     0.0675 Validation Accuracy: 0.620800\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.2146 Validation Accuracy: 0.612600\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     0.1755 Validation Accuracy: 0.621600\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     0.1818 Validation Accuracy: 0.615800\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     0.2139 Validation Accuracy: 0.619200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     0.0770 Validation Accuracy: 0.621200\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.2063 Validation Accuracy: 0.622400\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     0.1920 Validation Accuracy: 0.620400\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     0.1772 Validation Accuracy: 0.612600\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     0.2294 Validation Accuracy: 0.611000\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     0.0857 Validation Accuracy: 0.609400\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.1890 Validation Accuracy: 0.615000\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     0.1992 Validation Accuracy: 0.616400\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     0.1615 Validation Accuracy: 0.619400\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     0.2399 Validation Accuracy: 0.611200\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     0.0606 Validation Accuracy: 0.617200\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.2257 Validation Accuracy: 0.613600\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     0.1606 Validation Accuracy: 0.617600\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     0.1744 Validation Accuracy: 0.626400\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     0.2041 Validation Accuracy: 0.617000\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     0.0501 Validation Accuracy: 0.619600\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.2005 Validation Accuracy: 0.619800\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     0.1651 Validation Accuracy: 0.620600\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     0.1963 Validation Accuracy: 0.616400\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     0.2384 Validation Accuracy: 0.615800\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     0.0610 Validation Accuracy: 0.618200\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.2079 Validation Accuracy: 0.616200\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     0.1788 Validation Accuracy: 0.615200\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     0.1950 Validation Accuracy: 0.617200\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     0.2125 Validation Accuracy: 0.612400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     0.0570 Validation Accuracy: 0.620600\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.2132 Validation Accuracy: 0.613000\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     0.1680 Validation Accuracy: 0.619200\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     0.1679 Validation Accuracy: 0.610400\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     0.1920 Validation Accuracy: 0.610600\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     0.0732 Validation Accuracy: 0.615400\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.2053 Validation Accuracy: 0.616000\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     0.1624 Validation Accuracy: 0.618400\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     0.1617 Validation Accuracy: 0.618000\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     0.2015 Validation Accuracy: 0.616000\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     0.0577 Validation Accuracy: 0.620800\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.1905 Validation Accuracy: 0.620000\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     0.1763 Validation Accuracy: 0.622600\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     0.1734 Validation Accuracy: 0.614000\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     0.2129 Validation Accuracy: 0.615400\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     0.0576 Validation Accuracy: 0.620200\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.2018 Validation Accuracy: 0.621800\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     0.1794 Validation Accuracy: 0.619400\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     0.1579 Validation Accuracy: 0.619000\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     0.2058 Validation Accuracy: 0.617000\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     0.0545 Validation Accuracy: 0.621000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.1956 Validation Accuracy: 0.614400\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     0.1672 Validation Accuracy: 0.626200\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     0.1496 Validation Accuracy: 0.619400\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     0.2048 Validation Accuracy: 0.617800\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     0.0582 Validation Accuracy: 0.619200\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.1827 Validation Accuracy: 0.612600\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     0.1603 Validation Accuracy: 0.624600\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     0.1679 Validation Accuracy: 0.612600\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     0.1965 Validation Accuracy: 0.619800\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     0.0551 Validation Accuracy: 0.625800\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.1800 Validation Accuracy: 0.618200\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     0.1880 Validation Accuracy: 0.625200\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     0.1639 Validation Accuracy: 0.617000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     0.2203 Validation Accuracy: 0.613200\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     0.0559 Validation Accuracy: 0.618600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.1885 Validation Accuracy: 0.614800\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     0.1613 Validation Accuracy: 0.618200\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     0.1565 Validation Accuracy: 0.616000\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     0.2014 Validation Accuracy: 0.619600\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     0.0587 Validation Accuracy: 0.624800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.1863 Validation Accuracy: 0.615200\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     0.1729 Validation Accuracy: 0.620600\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     0.1541 Validation Accuracy: 0.620000\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     0.1995 Validation Accuracy: 0.611400\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     0.0486 Validation Accuracy: 0.619000\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.1745 Validation Accuracy: 0.614600\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     0.1476 Validation Accuracy: 0.618000\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     0.1417 Validation Accuracy: 0.609800\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     0.1967 Validation Accuracy: 0.613400\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     0.0570 Validation Accuracy: 0.617600\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.1915 Validation Accuracy: 0.616000\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     0.1641 Validation Accuracy: 0.616600\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     0.1238 Validation Accuracy: 0.613200\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     0.2052 Validation Accuracy: 0.610800\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     0.0589 Validation Accuracy: 0.618600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.1755 Validation Accuracy: 0.618600\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     0.1666 Validation Accuracy: 0.613200\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     0.1329 Validation Accuracy: 0.618200\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     0.1890 Validation Accuracy: 0.614600\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     0.0527 Validation Accuracy: 0.620200\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.1712 Validation Accuracy: 0.616800\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     0.1454 Validation Accuracy: 0.618400\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     0.1358 Validation Accuracy: 0.620600\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     0.1943 Validation Accuracy: 0.620800\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     0.0487 Validation Accuracy: 0.615400\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.1727 Validation Accuracy: 0.618000\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     0.1323 Validation Accuracy: 0.621600\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     0.1563 Validation Accuracy: 0.613800\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     0.1871 Validation Accuracy: 0.611200\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     0.0469 Validation Accuracy: 0.617200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.1649 Validation Accuracy: 0.615200\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     0.1653 Validation Accuracy: 0.618600\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     0.1258 Validation Accuracy: 0.615600\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     0.1901 Validation Accuracy: 0.616000\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     0.0496 Validation Accuracy: 0.624200\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.1626 Validation Accuracy: 0.616600\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     0.1654 Validation Accuracy: 0.625600\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     0.1120 Validation Accuracy: 0.618400\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     0.1871 Validation Accuracy: 0.620000\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     0.0830 Validation Accuracy: 0.616800\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.1737 Validation Accuracy: 0.615400\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     0.1288 Validation Accuracy: 0.622800\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     0.1284 Validation Accuracy: 0.622800\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     0.2067 Validation Accuracy: 0.616200\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     0.0593 Validation Accuracy: 0.612000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.1694 Validation Accuracy: 0.616200\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     0.1513 Validation Accuracy: 0.618800\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     0.1157 Validation Accuracy: 0.624000\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     0.2026 Validation Accuracy: 0.621600\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     0.0322 Validation Accuracy: 0.620200\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.1661 Validation Accuracy: 0.615000\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     0.1227 Validation Accuracy: 0.616800\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     0.1199 Validation Accuracy: 0.619400\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     0.1979 Validation Accuracy: 0.624000\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     0.0494 Validation Accuracy: 0.622000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.1517 Validation Accuracy: 0.619800\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     0.1255 Validation Accuracy: 0.617400\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     0.1114 Validation Accuracy: 0.620400\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     0.1863 Validation Accuracy: 0.623200\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     0.0466 Validation Accuracy: 0.622400\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.1697 Validation Accuracy: 0.618600\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     0.1426 Validation Accuracy: 0.620200\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     0.1281 Validation Accuracy: 0.622600\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     0.1922 Validation Accuracy: 0.624600\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     0.0573 Validation Accuracy: 0.617200\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.1662 Validation Accuracy: 0.622400\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     0.1146 Validation Accuracy: 0.622800\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     0.1235 Validation Accuracy: 0.616600\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     0.1936 Validation Accuracy: 0.619000\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     0.0441 Validation Accuracy: 0.619200\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.1804 Validation Accuracy: 0.615800\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     0.1575 Validation Accuracy: 0.618200\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     0.1285 Validation Accuracy: 0.618600\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     0.1877 Validation Accuracy: 0.606200\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     0.0426 Validation Accuracy: 0.619800\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.1556 Validation Accuracy: 0.617600\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     0.1720 Validation Accuracy: 0.621200\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     0.1477 Validation Accuracy: 0.616000\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     0.1922 Validation Accuracy: 0.621400\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     0.0451 Validation Accuracy: 0.627200\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.1531 Validation Accuracy: 0.615200\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     0.1347 Validation Accuracy: 0.622400\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     0.1138 Validation Accuracy: 0.620800\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     0.1943 Validation Accuracy: 0.624800\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     0.0518 Validation Accuracy: 0.620600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.1656 Validation Accuracy: 0.614600\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     0.1143 Validation Accuracy: 0.622800\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     0.1228 Validation Accuracy: 0.614000\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     0.2015 Validation Accuracy: 0.610200\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     0.0390 Validation Accuracy: 0.616400\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.1545 Validation Accuracy: 0.619800\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     0.1053 Validation Accuracy: 0.620400\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     0.1212 Validation Accuracy: 0.618200\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     0.2050 Validation Accuracy: 0.612800\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     0.0467 Validation Accuracy: 0.622200\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.1527 Validation Accuracy: 0.613000\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     0.1087 Validation Accuracy: 0.612200\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     0.1361 Validation Accuracy: 0.618000\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     0.1823 Validation Accuracy: 0.618600\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     0.0356 Validation Accuracy: 0.617800\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.1661 Validation Accuracy: 0.610600\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     0.1147 Validation Accuracy: 0.616600\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     0.0918 Validation Accuracy: 0.615600\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     0.1873 Validation Accuracy: 0.619600\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     0.0373 Validation Accuracy: 0.618600\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.1484 Validation Accuracy: 0.618000\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     0.1186 Validation Accuracy: 0.621600\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     0.1092 Validation Accuracy: 0.617800\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     0.1897 Validation Accuracy: 0.620400\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     0.0402 Validation Accuracy: 0.619000\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.1326 Validation Accuracy: 0.608400\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     0.1359 Validation Accuracy: 0.618600\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     0.1484 Validation Accuracy: 0.617200\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     0.1842 Validation Accuracy: 0.622200\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     0.0283 Validation Accuracy: 0.621200\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.1426 Validation Accuracy: 0.607200\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     0.1423 Validation Accuracy: 0.613600\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     0.0907 Validation Accuracy: 0.621400\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     0.1874 Validation Accuracy: 0.617600\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     0.0366 Validation Accuracy: 0.615800\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.1623 Validation Accuracy: 0.619800\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     0.1240 Validation Accuracy: 0.627600\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     0.1012 Validation Accuracy: 0.621000\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     0.1852 Validation Accuracy: 0.623200\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     0.0431 Validation Accuracy: 0.613600\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.1404 Validation Accuracy: 0.620800\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     0.1738 Validation Accuracy: 0.616400\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     0.1109 Validation Accuracy: 0.621800\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     0.1806 Validation Accuracy: 0.626000\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     0.0490 Validation Accuracy: 0.615400\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.1428 Validation Accuracy: 0.619000\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     0.1193 Validation Accuracy: 0.620800\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     0.1046 Validation Accuracy: 0.616400\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     0.1812 Validation Accuracy: 0.617200\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     0.0398 Validation Accuracy: 0.622600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.1426 Validation Accuracy: 0.618200\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     0.1309 Validation Accuracy: 0.615800\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     0.1169 Validation Accuracy: 0.620800\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     0.1885 Validation Accuracy: 0.619800\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     0.0328 Validation Accuracy: 0.622200\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.1405 Validation Accuracy: 0.610600\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     0.1438 Validation Accuracy: 0.618000\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     0.1047 Validation Accuracy: 0.623400\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     0.1782 Validation Accuracy: 0.626000\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     0.0364 Validation Accuracy: 0.624600\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.1346 Validation Accuracy: 0.615200\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     0.1134 Validation Accuracy: 0.623200\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     0.1100 Validation Accuracy: 0.613000\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     0.1766 Validation Accuracy: 0.623600\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     0.0336 Validation Accuracy: 0.626600\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.1270 Validation Accuracy: 0.614000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     0.1311 Validation Accuracy: 0.617000\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     0.1142 Validation Accuracy: 0.618400\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     0.1775 Validation Accuracy: 0.614600\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     0.0284 Validation Accuracy: 0.615000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.1343 Validation Accuracy: 0.619600\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     0.1118 Validation Accuracy: 0.616400\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     0.0932 Validation Accuracy: 0.618000\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     0.1802 Validation Accuracy: 0.620200\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     0.0366 Validation Accuracy: 0.623400\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.1263 Validation Accuracy: 0.618200\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     0.1181 Validation Accuracy: 0.615000\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     0.0899 Validation Accuracy: 0.622000\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     0.1931 Validation Accuracy: 0.618600\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     0.0384 Validation Accuracy: 0.617200\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.1314 Validation Accuracy: 0.618200\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     0.1114 Validation Accuracy: 0.621200\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     0.0906 Validation Accuracy: 0.619400\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     0.1866 Validation Accuracy: 0.621000\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     0.0355 Validation Accuracy: 0.615000\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.1350 Validation Accuracy: 0.617400\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     0.1057 Validation Accuracy: 0.615200\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     0.1010 Validation Accuracy: 0.614000\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     0.1821 Validation Accuracy: 0.618200\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     0.0397 Validation Accuracy: 0.617800\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.1366 Validation Accuracy: 0.613800\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     0.1191 Validation Accuracy: 0.624400\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     0.1038 Validation Accuracy: 0.621800\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     0.1787 Validation Accuracy: 0.627400\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     0.0332 Validation Accuracy: 0.628200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.1361 Validation Accuracy: 0.623000\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     0.1316 Validation Accuracy: 0.621800\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     0.0888 Validation Accuracy: 0.618400\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     0.1856 Validation Accuracy: 0.621000\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     0.0357 Validation Accuracy: 0.617400\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.1348 Validation Accuracy: 0.618600\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     0.1431 Validation Accuracy: 0.618600\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     0.1021 Validation Accuracy: 0.619600\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     0.1790 Validation Accuracy: 0.621600\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     0.0323 Validation Accuracy: 0.619800\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.1387 Validation Accuracy: 0.615600\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     0.0981 Validation Accuracy: 0.621600\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     0.0948 Validation Accuracy: 0.613800\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     0.1727 Validation Accuracy: 0.610200\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     0.0410 Validation Accuracy: 0.620000\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.1523 Validation Accuracy: 0.618200\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     0.1129 Validation Accuracy: 0.607200\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     0.1097 Validation Accuracy: 0.614000\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     0.1533 Validation Accuracy: 0.623200\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     0.0282 Validation Accuracy: 0.618400\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.1385 Validation Accuracy: 0.613600\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     0.0909 Validation Accuracy: 0.621600\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     0.0861 Validation Accuracy: 0.617600\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     0.1493 Validation Accuracy: 0.619000\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     0.0271 Validation Accuracy: 0.621200\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.1243 Validation Accuracy: 0.617800\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     0.1052 Validation Accuracy: 0.619200\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     0.0997 Validation Accuracy: 0.619400\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     0.1769 Validation Accuracy: 0.617400\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     0.0218 Validation Accuracy: 0.617600\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.1315 Validation Accuracy: 0.617000\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     0.1023 Validation Accuracy: 0.620000\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     0.0952 Validation Accuracy: 0.616800\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     0.1737 Validation Accuracy: 0.616400\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     0.0298 Validation Accuracy: 0.621600\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.1217 Validation Accuracy: 0.614600\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     0.1068 Validation Accuracy: 0.621200\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     0.0875 Validation Accuracy: 0.620000\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     0.1696 Validation Accuracy: 0.611800\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     0.0227 Validation Accuracy: 0.620000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.1311 Validation Accuracy: 0.616400\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     0.1058 Validation Accuracy: 0.617600\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     0.0705 Validation Accuracy: 0.619600\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     0.1753 Validation Accuracy: 0.617000\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     0.0257 Validation Accuracy: 0.620800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.1254 Validation Accuracy: 0.617000\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     0.0908 Validation Accuracy: 0.618200\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     0.0856 Validation Accuracy: 0.614800\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     0.1594 Validation Accuracy: 0.619800\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     0.0222 Validation Accuracy: 0.623600\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.1312 Validation Accuracy: 0.614000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     0.0792 Validation Accuracy: 0.621800\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     0.0964 Validation Accuracy: 0.621400\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     0.1405 Validation Accuracy: 0.621800\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     0.0216 Validation Accuracy: 0.621000\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.1360 Validation Accuracy: 0.615400\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     0.0906 Validation Accuracy: 0.615000\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     0.0817 Validation Accuracy: 0.615200\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     0.1643 Validation Accuracy: 0.621800\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     0.0265 Validation Accuracy: 0.619000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.1432 Validation Accuracy: 0.608200\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     0.0784 Validation Accuracy: 0.616400\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     0.0763 Validation Accuracy: 0.619600\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     0.1690 Validation Accuracy: 0.621200\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     0.0240 Validation Accuracy: 0.615800\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.1175 Validation Accuracy: 0.618400\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     0.0795 Validation Accuracy: 0.615000\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     0.0793 Validation Accuracy: 0.612000\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     0.1756 Validation Accuracy: 0.620800\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     0.0267 Validation Accuracy: 0.623000\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.1294 Validation Accuracy: 0.615200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     0.0858 Validation Accuracy: 0.613200\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     0.0879 Validation Accuracy: 0.617600\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     0.1819 Validation Accuracy: 0.612400\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     0.0213 Validation Accuracy: 0.618800\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.1295 Validation Accuracy: 0.618200\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     0.0766 Validation Accuracy: 0.617400\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     0.0951 Validation Accuracy: 0.616400\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     0.1636 Validation Accuracy: 0.617200\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     0.0188 Validation Accuracy: 0.619000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.1120 Validation Accuracy: 0.618400\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     0.0827 Validation Accuracy: 0.620000\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     0.0819 Validation Accuracy: 0.613000\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     0.1545 Validation Accuracy: 0.622200\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     0.0213 Validation Accuracy: 0.617600\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.1129 Validation Accuracy: 0.615000\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     0.0892 Validation Accuracy: 0.620000\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     0.1073 Validation Accuracy: 0.614400\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     0.1736 Validation Accuracy: 0.619400\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     0.0246 Validation Accuracy: 0.620400\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.1284 Validation Accuracy: 0.616000\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     0.0884 Validation Accuracy: 0.616400\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     0.1005 Validation Accuracy: 0.615600\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     0.1589 Validation Accuracy: 0.615200\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     0.0173 Validation Accuracy: 0.616600\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.1160 Validation Accuracy: 0.614000\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     0.1151 Validation Accuracy: 0.614400\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     0.0895 Validation Accuracy: 0.613000\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     0.1698 Validation Accuracy: 0.623600\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     0.0225 Validation Accuracy: 0.623000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.1113 Validation Accuracy: 0.617200\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     0.0843 Validation Accuracy: 0.609400\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     0.0916 Validation Accuracy: 0.617400\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     0.1620 Validation Accuracy: 0.621200\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     0.0153 Validation Accuracy: 0.618400\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     0.1228 Validation Accuracy: 0.618400\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     0.0780 Validation Accuracy: 0.619800\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     0.0705 Validation Accuracy: 0.618000\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     0.1656 Validation Accuracy: 0.622800\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     0.0206 Validation Accuracy: 0.621000\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     0.1268 Validation Accuracy: 0.622400\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     0.0932 Validation Accuracy: 0.621000\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     0.0778 Validation Accuracy: 0.619000\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     0.1605 Validation Accuracy: 0.613600\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     0.0233 Validation Accuracy: 0.618000\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     0.1207 Validation Accuracy: 0.617200\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     0.1122 Validation Accuracy: 0.617800\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     0.0789 Validation Accuracy: 0.613200\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     0.1293 Validation Accuracy: 0.618400\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     0.0209 Validation Accuracy: 0.616200\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     0.1265 Validation Accuracy: 0.619600\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     0.0770 Validation Accuracy: 0.628200\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     0.0934 Validation Accuracy: 0.617800\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     0.1577 Validation Accuracy: 0.621000\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     0.0241 Validation Accuracy: 0.625400\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     0.1228 Validation Accuracy: 0.621800\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     0.0910 Validation Accuracy: 0.619600\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     0.0750 Validation Accuracy: 0.615400\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     0.1350 Validation Accuracy: 0.623800\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     0.0133 Validation Accuracy: 0.619400\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     0.1284 Validation Accuracy: 0.623000\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     0.0863 Validation Accuracy: 0.617800\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     0.0729 Validation Accuracy: 0.611400\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     0.1422 Validation Accuracy: 0.617600\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     0.0161 Validation Accuracy: 0.619200\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     0.1139 Validation Accuracy: 0.624800\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     0.0694 Validation Accuracy: 0.622600\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     0.0830 Validation Accuracy: 0.617400\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     0.1444 Validation Accuracy: 0.624000\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     0.0133 Validation Accuracy: 0.617000\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     0.1145 Validation Accuracy: 0.620200\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     0.0811 Validation Accuracy: 0.616600\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     0.0705 Validation Accuracy: 0.618400\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     0.1335 Validation Accuracy: 0.612400\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     0.0176 Validation Accuracy: 0.620800\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     0.1186 Validation Accuracy: 0.616200\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     0.0799 Validation Accuracy: 0.613800\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     0.0745 Validation Accuracy: 0.616600\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     0.1209 Validation Accuracy: 0.618600\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     0.0137 Validation Accuracy: 0.614800\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     0.1169 Validation Accuracy: 0.613800\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     0.0790 Validation Accuracy: 0.619600\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     0.0780 Validation Accuracy: 0.614600\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     0.1381 Validation Accuracy: 0.619600\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     0.0223 Validation Accuracy: 0.620200\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     0.1228 Validation Accuracy: 0.614800\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     0.0756 Validation Accuracy: 0.617200\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     0.0749 Validation Accuracy: 0.616600\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     0.1242 Validation Accuracy: 0.621000\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     0.0264 Validation Accuracy: 0.619000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     0.1191 Validation Accuracy: 0.625600\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     0.0702 Validation Accuracy: 0.621000\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     0.0793 Validation Accuracy: 0.621400\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     0.1238 Validation Accuracy: 0.622800\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     0.0221 Validation Accuracy: 0.619000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     0.1465 Validation Accuracy: 0.617400\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     0.0690 Validation Accuracy: 0.619400\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     0.0809 Validation Accuracy: 0.618400\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     0.1189 Validation Accuracy: 0.617400\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     0.0204 Validation Accuracy: 0.622800\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     0.1090 Validation Accuracy: 0.612800\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     0.0893 Validation Accuracy: 0.619400\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     0.0666 Validation Accuracy: 0.612600\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     0.1287 Validation Accuracy: 0.619400\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     0.0260 Validation Accuracy: 0.616400\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     0.1117 Validation Accuracy: 0.618400\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     0.0843 Validation Accuracy: 0.624800\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     0.0715 Validation Accuracy: 0.625600\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     0.1241 Validation Accuracy: 0.623200\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     0.0207 Validation Accuracy: 0.620000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     0.1293 Validation Accuracy: 0.612800\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     0.0713 Validation Accuracy: 0.614800\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     0.0731 Validation Accuracy: 0.617800\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     0.1300 Validation Accuracy: 0.617600\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     0.0182 Validation Accuracy: 0.618200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     0.1105 Validation Accuracy: 0.611800\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     0.0806 Validation Accuracy: 0.619800\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     0.0807 Validation Accuracy: 0.617200\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     0.1396 Validation Accuracy: 0.614800\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     0.0159 Validation Accuracy: 0.618600\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     0.1192 Validation Accuracy: 0.621600\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     0.0663 Validation Accuracy: 0.617200\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     0.0804 Validation Accuracy: 0.616800\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     0.1321 Validation Accuracy: 0.620600\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     0.0248 Validation Accuracy: 0.613600\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     0.1137 Validation Accuracy: 0.616000\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     0.0655 Validation Accuracy: 0.624800\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     0.0645 Validation Accuracy: 0.614800\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     0.1277 Validation Accuracy: 0.617800\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     0.0124 Validation Accuracy: 0.615000\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     0.1073 Validation Accuracy: 0.613400\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     0.0737 Validation Accuracy: 0.624000\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     0.0631 Validation Accuracy: 0.619800\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     0.1110 Validation Accuracy: 0.617200\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     0.0111 Validation Accuracy: 0.616800\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     0.1094 Validation Accuracy: 0.614400\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     0.0709 Validation Accuracy: 0.620200\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     0.0657 Validation Accuracy: 0.617600\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     0.1213 Validation Accuracy: 0.621600\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     0.0179 Validation Accuracy: 0.618400\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     0.1036 Validation Accuracy: 0.618200\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     0.0769 Validation Accuracy: 0.618000\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     0.0678 Validation Accuracy: 0.613600\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     0.1296 Validation Accuracy: 0.620800\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     0.0178 Validation Accuracy: 0.620200\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     0.1189 Validation Accuracy: 0.616600\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     0.0582 Validation Accuracy: 0.620600\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     0.0862 Validation Accuracy: 0.612400\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     0.1170 Validation Accuracy: 0.621400\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     0.0225 Validation Accuracy: 0.623000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     0.1175 Validation Accuracy: 0.617400\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     0.0789 Validation Accuracy: 0.618000\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     0.0698 Validation Accuracy: 0.620400\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     0.1219 Validation Accuracy: 0.617400\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     0.0125 Validation Accuracy: 0.618400\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     0.1097 Validation Accuracy: 0.620600\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     0.0673 Validation Accuracy: 0.623600\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     0.0812 Validation Accuracy: 0.613000\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     0.1231 Validation Accuracy: 0.623600\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     0.0179 Validation Accuracy: 0.621200\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     0.1075 Validation Accuracy: 0.621000\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     0.0619 Validation Accuracy: 0.618000\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     0.0709 Validation Accuracy: 0.618000\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     0.1235 Validation Accuracy: 0.620200\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     0.0137 Validation Accuracy: 0.617400\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     0.1072 Validation Accuracy: 0.613000\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     0.0676 Validation Accuracy: 0.619400\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     0.0660 Validation Accuracy: 0.620400\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     0.1304 Validation Accuracy: 0.620000\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     0.0154 Validation Accuracy: 0.618800\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     0.1254 Validation Accuracy: 0.617200\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     0.0487 Validation Accuracy: 0.624400\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     0.0693 Validation Accuracy: 0.617400\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     0.1133 Validation Accuracy: 0.618200\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     0.0122 Validation Accuracy: 0.620200\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     0.1098 Validation Accuracy: 0.616600\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     0.0495 Validation Accuracy: 0.617800\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     0.0678 Validation Accuracy: 0.617800\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     0.1118 Validation Accuracy: 0.617800\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     0.0140 Validation Accuracy: 0.621400\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     0.1239 Validation Accuracy: 0.612000\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     0.0627 Validation Accuracy: 0.614400\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     0.0654 Validation Accuracy: 0.616800\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     0.1112 Validation Accuracy: 0.621800\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     0.0117 Validation Accuracy: 0.618800\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     0.1186 Validation Accuracy: 0.616400\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     0.0437 Validation Accuracy: 0.619600\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     0.0672 Validation Accuracy: 0.613600\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     0.1114 Validation Accuracy: 0.622800\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     0.0192 Validation Accuracy: 0.615600\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     0.1245 Validation Accuracy: 0.612000\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     0.0532 Validation Accuracy: 0.617600\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     0.0728 Validation Accuracy: 0.616200\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     0.1149 Validation Accuracy: 0.617200\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     0.0179 Validation Accuracy: 0.614200\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     0.1221 Validation Accuracy: 0.609400\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     0.0579 Validation Accuracy: 0.617800\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     0.0740 Validation Accuracy: 0.614600\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     0.1212 Validation Accuracy: 0.618400\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     0.0127 Validation Accuracy: 0.616800\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     0.1066 Validation Accuracy: 0.613200\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     0.0622 Validation Accuracy: 0.610600\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     0.0736 Validation Accuracy: 0.613000\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     0.1115 Validation Accuracy: 0.623000\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     0.0216 Validation Accuracy: 0.624600\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     0.1100 Validation Accuracy: 0.615200\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     0.0648 Validation Accuracy: 0.620400\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     0.0755 Validation Accuracy: 0.616200\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     0.1240 Validation Accuracy: 0.620800\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     0.0134 Validation Accuracy: 0.618200\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     0.1187 Validation Accuracy: 0.613800\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     0.0478 Validation Accuracy: 0.615600\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     0.0789 Validation Accuracy: 0.612000\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     0.1154 Validation Accuracy: 0.624200\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     0.0186 Validation Accuracy: 0.616200\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     0.1246 Validation Accuracy: 0.615400\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     0.0522 Validation Accuracy: 0.610200\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     0.0741 Validation Accuracy: 0.613600\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     0.1189 Validation Accuracy: 0.610600\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     0.0202 Validation Accuracy: 0.621800\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     0.1179 Validation Accuracy: 0.613600\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     0.0443 Validation Accuracy: 0.612400\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     0.0702 Validation Accuracy: 0.619000\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     0.1187 Validation Accuracy: 0.619200\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     0.0139 Validation Accuracy: 0.626200\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     0.1263 Validation Accuracy: 0.614600\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     0.0463 Validation Accuracy: 0.614400\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     0.0638 Validation Accuracy: 0.614400\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     0.1116 Validation Accuracy: 0.619600\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     0.0164 Validation Accuracy: 0.618800\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     0.1210 Validation Accuracy: 0.609800\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     0.0527 Validation Accuracy: 0.621600\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     0.0628 Validation Accuracy: 0.618600\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     0.1142 Validation Accuracy: 0.614000\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.613000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     0.1053 Validation Accuracy: 0.613800\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     0.0643 Validation Accuracy: 0.616200\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     0.0777 Validation Accuracy: 0.617200\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     0.1198 Validation Accuracy: 0.620200\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     0.0138 Validation Accuracy: 0.615800\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     0.1174 Validation Accuracy: 0.613800\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     0.0398 Validation Accuracy: 0.615200\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     0.0624 Validation Accuracy: 0.620200\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     0.1399 Validation Accuracy: 0.617800\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     0.0129 Validation Accuracy: 0.618000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     0.1123 Validation Accuracy: 0.613000\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     0.0498 Validation Accuracy: 0.615800\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     0.0699 Validation Accuracy: 0.613400\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     0.1075 Validation Accuracy: 0.615600\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     0.0217 Validation Accuracy: 0.622000\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     0.1187 Validation Accuracy: 0.615200\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     0.0584 Validation Accuracy: 0.619600\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     0.0706 Validation Accuracy: 0.615200\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     0.1244 Validation Accuracy: 0.615800\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     0.0140 Validation Accuracy: 0.623800\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     0.1155 Validation Accuracy: 0.618600\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     0.0477 Validation Accuracy: 0.620600\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     0.0575 Validation Accuracy: 0.615200\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     0.1117 Validation Accuracy: 0.622800\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     0.0124 Validation Accuracy: 0.618200\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     0.1098 Validation Accuracy: 0.617400\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     0.0408 Validation Accuracy: 0.618400\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     0.0645 Validation Accuracy: 0.618200\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     0.1149 Validation Accuracy: 0.618000\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     0.0162 Validation Accuracy: 0.620000\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     0.1062 Validation Accuracy: 0.621600\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     0.0377 Validation Accuracy: 0.624800\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     0.0642 Validation Accuracy: 0.620400\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     0.1082 Validation Accuracy: 0.614600\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     0.0095 Validation Accuracy: 0.615800\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     0.1194 Validation Accuracy: 0.611800\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     0.0455 Validation Accuracy: 0.618600\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     0.0638 Validation Accuracy: 0.612400\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     0.1179 Validation Accuracy: 0.621200\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     0.0164 Validation Accuracy: 0.619200\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     0.1148 Validation Accuracy: 0.619200\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     0.0432 Validation Accuracy: 0.617600\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     0.0631 Validation Accuracy: 0.615600\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     0.1092 Validation Accuracy: 0.612800\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     0.0134 Validation Accuracy: 0.612600\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     0.1082 Validation Accuracy: 0.608200\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     0.0371 Validation Accuracy: 0.615200\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     0.0644 Validation Accuracy: 0.613200\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     0.1130 Validation Accuracy: 0.616000\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     0.0110 Validation Accuracy: 0.619600\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     0.1170 Validation Accuracy: 0.617400\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     0.0400 Validation Accuracy: 0.616400\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     0.0595 Validation Accuracy: 0.617400\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     0.1143 Validation Accuracy: 0.615400\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     0.0089 Validation Accuracy: 0.615200\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     0.1197 Validation Accuracy: 0.615200\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     0.0500 Validation Accuracy: 0.617800\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     0.0669 Validation Accuracy: 0.615200\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     0.1087 Validation Accuracy: 0.617600\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     0.0158 Validation Accuracy: 0.619800\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     0.1243 Validation Accuracy: 0.619600\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     0.0440 Validation Accuracy: 0.620600\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     0.0670 Validation Accuracy: 0.613200\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     0.1125 Validation Accuracy: 0.613600\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     0.0155 Validation Accuracy: 0.617600\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     0.1109 Validation Accuracy: 0.612800\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     0.0505 Validation Accuracy: 0.616200\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     0.0623 Validation Accuracy: 0.622000\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     0.1114 Validation Accuracy: 0.617600\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     0.0136 Validation Accuracy: 0.623600\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     0.1046 Validation Accuracy: 0.615200\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     0.0448 Validation Accuracy: 0.610800\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     0.0582 Validation Accuracy: 0.617200\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     0.1051 Validation Accuracy: 0.614800\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     0.0093 Validation Accuracy: 0.620000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     0.1072 Validation Accuracy: 0.609400\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     0.0396 Validation Accuracy: 0.613800\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     0.0623 Validation Accuracy: 0.615200\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     0.1097 Validation Accuracy: 0.625600\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     0.0123 Validation Accuracy: 0.620800\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     0.1102 Validation Accuracy: 0.611400\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     0.0409 Validation Accuracy: 0.612600\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     0.0623 Validation Accuracy: 0.616200\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     0.1079 Validation Accuracy: 0.614600\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     0.0193 Validation Accuracy: 0.615000\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     0.1098 Validation Accuracy: 0.617000\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     0.0371 Validation Accuracy: 0.620600\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     0.0627 Validation Accuracy: 0.611800\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     0.1057 Validation Accuracy: 0.620400\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     0.0104 Validation Accuracy: 0.624400\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     0.1059 Validation Accuracy: 0.604600\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     0.0350 Validation Accuracy: 0.614800\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     0.0630 Validation Accuracy: 0.620400\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     0.1068 Validation Accuracy: 0.623200\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     0.0114 Validation Accuracy: 0.614400\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     0.1041 Validation Accuracy: 0.614000\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     0.0360 Validation Accuracy: 0.613800\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     0.0572 Validation Accuracy: 0.618200\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     0.1120 Validation Accuracy: 0.619400\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     0.0177 Validation Accuracy: 0.615800\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     0.1019 Validation Accuracy: 0.614400\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     0.0354 Validation Accuracy: 0.622600\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     0.0611 Validation Accuracy: 0.618200\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     0.1101 Validation Accuracy: 0.616000\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     0.0192 Validation Accuracy: 0.615600\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     0.1137 Validation Accuracy: 0.617200\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     0.0415 Validation Accuracy: 0.607800\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     0.0657 Validation Accuracy: 0.611200\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     0.1121 Validation Accuracy: 0.612600\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     0.0096 Validation Accuracy: 0.618600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     0.0995 Validation Accuracy: 0.601000\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     0.0372 Validation Accuracy: 0.617000\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     0.0649 Validation Accuracy: 0.614600\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     0.1091 Validation Accuracy: 0.616400\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     0.0177 Validation Accuracy: 0.611400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     0.1025 Validation Accuracy: 0.616400\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     0.0374 Validation Accuracy: 0.611400\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     0.0564 Validation Accuracy: 0.618200\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     0.1126 Validation Accuracy: 0.617400\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     0.0189 Validation Accuracy: 0.618000\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     0.1175 Validation Accuracy: 0.609000\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     0.0339 Validation Accuracy: 0.611400\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     0.0527 Validation Accuracy: 0.613400\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     0.1063 Validation Accuracy: 0.618800\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     0.0164 Validation Accuracy: 0.615600\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     0.1107 Validation Accuracy: 0.612200\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     0.0353 Validation Accuracy: 0.620400\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     0.0562 Validation Accuracy: 0.622400\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     0.0892 Validation Accuracy: 0.615200\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     0.0103 Validation Accuracy: 0.612800\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     0.1023 Validation Accuracy: 0.612200\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     0.0330 Validation Accuracy: 0.606200\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     0.0608 Validation Accuracy: 0.613600\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     0.0935 Validation Accuracy: 0.618600\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     0.0144 Validation Accuracy: 0.620000\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     0.1095 Validation Accuracy: 0.617600\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     0.0379 Validation Accuracy: 0.619400\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     0.0666 Validation Accuracy: 0.616600\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     0.1036 Validation Accuracy: 0.614200\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     0.0154 Validation Accuracy: 0.620800\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     0.1198 Validation Accuracy: 0.617200\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     0.0353 Validation Accuracy: 0.614400\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     0.0570 Validation Accuracy: 0.617000\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     0.1037 Validation Accuracy: 0.615200\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     0.0140 Validation Accuracy: 0.623200\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     0.0996 Validation Accuracy: 0.619000\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     0.0357 Validation Accuracy: 0.623800\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     0.0532 Validation Accuracy: 0.622800\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     0.1070 Validation Accuracy: 0.620800\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     0.0168 Validation Accuracy: 0.619800\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     0.1093 Validation Accuracy: 0.615000\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     0.0388 Validation Accuracy: 0.615800\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     0.0566 Validation Accuracy: 0.615000\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     0.1082 Validation Accuracy: 0.615800\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     0.0186 Validation Accuracy: 0.611400\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     0.1074 Validation Accuracy: 0.616200\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     0.0315 Validation Accuracy: 0.617400\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     0.0579 Validation Accuracy: 0.615400\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     0.1075 Validation Accuracy: 0.619200\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     0.0086 Validation Accuracy: 0.618400\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     0.0993 Validation Accuracy: 0.609400\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     0.0373 Validation Accuracy: 0.610000\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     0.0616 Validation Accuracy: 0.617800\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     0.0999 Validation Accuracy: 0.616800\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     0.0109 Validation Accuracy: 0.617200\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     0.0936 Validation Accuracy: 0.610000\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     0.0312 Validation Accuracy: 0.606600\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     0.0602 Validation Accuracy: 0.621800\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     0.1040 Validation Accuracy: 0.618200\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     0.0084 Validation Accuracy: 0.622600\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     0.1278 Validation Accuracy: 0.620800\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     0.0349 Validation Accuracy: 0.620800\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     0.0592 Validation Accuracy: 0.618600\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     0.1012 Validation Accuracy: 0.615400\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     0.0112 Validation Accuracy: 0.618200\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     0.1030 Validation Accuracy: 0.616000\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     0.0387 Validation Accuracy: 0.618200\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     0.0568 Validation Accuracy: 0.619400\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     0.0984 Validation Accuracy: 0.613200\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     0.0072 Validation Accuracy: 0.622800\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     0.1181 Validation Accuracy: 0.617800\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     0.0333 Validation Accuracy: 0.620600\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     0.0527 Validation Accuracy: 0.617000\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     0.1000 Validation Accuracy: 0.615800\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     0.0090 Validation Accuracy: 0.618800\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     0.1093 Validation Accuracy: 0.615800\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     0.0337 Validation Accuracy: 0.616600\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     0.0543 Validation Accuracy: 0.618800\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     0.0928 Validation Accuracy: 0.610200\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     0.0109 Validation Accuracy: 0.621200\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     0.1198 Validation Accuracy: 0.615800\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     0.0354 Validation Accuracy: 0.615600\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     0.0596 Validation Accuracy: 0.617600\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     0.1052 Validation Accuracy: 0.616600\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     0.0091 Validation Accuracy: 0.619600\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     0.1130 Validation Accuracy: 0.610200\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     0.0333 Validation Accuracy: 0.612400\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     0.0529 Validation Accuracy: 0.619800\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     0.1102 Validation Accuracy: 0.615600\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     0.0152 Validation Accuracy: 0.621400\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     0.1078 Validation Accuracy: 0.612800\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     0.0314 Validation Accuracy: 0.614200\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     0.0561 Validation Accuracy: 0.617800\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     0.0933 Validation Accuracy: 0.618000\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     0.0129 Validation Accuracy: 0.617800\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     0.1089 Validation Accuracy: 0.612800\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     0.0327 Validation Accuracy: 0.608400\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     0.0527 Validation Accuracy: 0.616000\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     0.0809 Validation Accuracy: 0.618400\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     0.0140 Validation Accuracy: 0.619400\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     0.1237 Validation Accuracy: 0.611600\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     0.0366 Validation Accuracy: 0.622800\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     0.0595 Validation Accuracy: 0.612600\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     0.0893 Validation Accuracy: 0.618000\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     0.0120 Validation Accuracy: 0.617800\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     0.1181 Validation Accuracy: 0.619400\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     0.0401 Validation Accuracy: 0.613200\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     0.0543 Validation Accuracy: 0.621600\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     0.1009 Validation Accuracy: 0.620600\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     0.0092 Validation Accuracy: 0.622000\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     0.1084 Validation Accuracy: 0.610600\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     0.0340 Validation Accuracy: 0.609000\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     0.0493 Validation Accuracy: 0.617000\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     0.0992 Validation Accuracy: 0.616400\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     0.0078 Validation Accuracy: 0.619200\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     0.1088 Validation Accuracy: 0.608800\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     0.0356 Validation Accuracy: 0.616000\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     0.0514 Validation Accuracy: 0.616000\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     0.0980 Validation Accuracy: 0.613600\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.619000\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     0.1158 Validation Accuracy: 0.606600\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     0.0355 Validation Accuracy: 0.611800\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     0.0523 Validation Accuracy: 0.617800\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     0.0789 Validation Accuracy: 0.615800\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     0.0091 Validation Accuracy: 0.616400\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     0.1016 Validation Accuracy: 0.612800\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     0.0327 Validation Accuracy: 0.612200\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     0.0514 Validation Accuracy: 0.614200\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     0.0797 Validation Accuracy: 0.609200\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.618600\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     0.0987 Validation Accuracy: 0.612000\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     0.0328 Validation Accuracy: 0.613600\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     0.0561 Validation Accuracy: 0.622800\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     0.1022 Validation Accuracy: 0.618400\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     0.0103 Validation Accuracy: 0.620200\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     0.1128 Validation Accuracy: 0.610800\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     0.0372 Validation Accuracy: 0.615600\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     0.0506 Validation Accuracy: 0.624000\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     0.0805 Validation Accuracy: 0.609600\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     0.0084 Validation Accuracy: 0.619200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     0.1136 Validation Accuracy: 0.612400\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     0.0361 Validation Accuracy: 0.615000\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     0.0548 Validation Accuracy: 0.617800\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     0.1000 Validation Accuracy: 0.621000\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     0.0063 Validation Accuracy: 0.616600\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     0.1235 Validation Accuracy: 0.616600\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     0.0301 Validation Accuracy: 0.612800\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     0.0516 Validation Accuracy: 0.621400\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     0.0800 Validation Accuracy: 0.611600\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     0.0097 Validation Accuracy: 0.620000\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     0.1040 Validation Accuracy: 0.614600\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     0.0351 Validation Accuracy: 0.615200\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     0.0599 Validation Accuracy: 0.617400\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     0.0953 Validation Accuracy: 0.612000\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     0.0156 Validation Accuracy: 0.623000\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     0.0954 Validation Accuracy: 0.612000\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     0.0317 Validation Accuracy: 0.614200\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     0.0506 Validation Accuracy: 0.614800\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     0.1019 Validation Accuracy: 0.616200\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     0.0068 Validation Accuracy: 0.614600\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     0.1086 Validation Accuracy: 0.609200\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     0.0331 Validation Accuracy: 0.611800\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     0.0568 Validation Accuracy: 0.616600\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     0.1043 Validation Accuracy: 0.616600\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     0.0079 Validation Accuracy: 0.612600\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     0.1056 Validation Accuracy: 0.609600\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     0.0344 Validation Accuracy: 0.618200\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     0.0533 Validation Accuracy: 0.614800\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     0.0949 Validation Accuracy: 0.613200\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     0.0063 Validation Accuracy: 0.613600\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     0.0938 Validation Accuracy: 0.610000\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     0.0310 Validation Accuracy: 0.609600\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     0.0558 Validation Accuracy: 0.616200\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     0.0995 Validation Accuracy: 0.619400\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     0.0074 Validation Accuracy: 0.618200\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     0.1006 Validation Accuracy: 0.611800\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     0.0344 Validation Accuracy: 0.622800\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     0.0501 Validation Accuracy: 0.616800\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     0.1067 Validation Accuracy: 0.617000\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     0.0058 Validation Accuracy: 0.617400\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     0.0920 Validation Accuracy: 0.609800\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     0.0315 Validation Accuracy: 0.621600\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     0.0514 Validation Accuracy: 0.620400\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     0.1045 Validation Accuracy: 0.618200\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.619600\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     0.1017 Validation Accuracy: 0.615000\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     0.0315 Validation Accuracy: 0.616800\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     0.0500 Validation Accuracy: 0.620800\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     0.0993 Validation Accuracy: 0.618800\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     0.0074 Validation Accuracy: 0.616000\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     0.0924 Validation Accuracy: 0.616800\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     0.0318 Validation Accuracy: 0.615600\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     0.0511 Validation Accuracy: 0.619200\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     0.0999 Validation Accuracy: 0.617800\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.620600\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     0.1055 Validation Accuracy: 0.617400\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     0.0325 Validation Accuracy: 0.613000\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     0.0521 Validation Accuracy: 0.618800\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     0.0965 Validation Accuracy: 0.617000\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     0.0097 Validation Accuracy: 0.617400\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     0.0809 Validation Accuracy: 0.616000\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     0.0308 Validation Accuracy: 0.611800\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     0.0524 Validation Accuracy: 0.615200\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     0.0956 Validation Accuracy: 0.621400\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     0.0088 Validation Accuracy: 0.615400\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     0.0981 Validation Accuracy: 0.618800\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     0.0316 Validation Accuracy: 0.619600\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     0.0580 Validation Accuracy: 0.613800\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     0.0929 Validation Accuracy: 0.616800\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     0.0125 Validation Accuracy: 0.608200\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     0.0940 Validation Accuracy: 0.615600\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     0.0317 Validation Accuracy: 0.617600\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     0.0514 Validation Accuracy: 0.619200\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     0.0939 Validation Accuracy: 0.621000\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     0.0080 Validation Accuracy: 0.617200\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     0.0981 Validation Accuracy: 0.615200\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     0.0310 Validation Accuracy: 0.618400\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     0.0489 Validation Accuracy: 0.625200\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     0.0946 Validation Accuracy: 0.615800\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     0.0073 Validation Accuracy: 0.615800\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     0.0898 Validation Accuracy: 0.619600\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     0.0352 Validation Accuracy: 0.615000\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     0.0534 Validation Accuracy: 0.619000\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     0.0654 Validation Accuracy: 0.614000\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.616400\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     0.0868 Validation Accuracy: 0.615400\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     0.0334 Validation Accuracy: 0.612000\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     0.0605 Validation Accuracy: 0.611600\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     0.0505 Validation Accuracy: 0.617000\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     0.0049 Validation Accuracy: 0.621200\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     0.0888 Validation Accuracy: 0.612400\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     0.0316 Validation Accuracy: 0.620000\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     0.0501 Validation Accuracy: 0.614800\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     0.0606 Validation Accuracy: 0.612600\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     0.0058 Validation Accuracy: 0.616800\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     0.0976 Validation Accuracy: 0.608800\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     0.0312 Validation Accuracy: 0.611600\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     0.0504 Validation Accuracy: 0.611600\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     0.0529 Validation Accuracy: 0.620800\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     0.0067 Validation Accuracy: 0.617200\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     0.0945 Validation Accuracy: 0.619800\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     0.0333 Validation Accuracy: 0.609000\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     0.0513 Validation Accuracy: 0.615000\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     0.0556 Validation Accuracy: 0.619200\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.619200\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     0.0980 Validation Accuracy: 0.619000\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     0.0323 Validation Accuracy: 0.612400\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     0.0497 Validation Accuracy: 0.620800\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     0.0483 Validation Accuracy: 0.616600\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     0.0099 Validation Accuracy: 0.620000\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     0.1012 Validation Accuracy: 0.614800\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     0.0329 Validation Accuracy: 0.622800\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     0.0492 Validation Accuracy: 0.626800\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     0.0536 Validation Accuracy: 0.618800\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     0.0064 Validation Accuracy: 0.620600\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     0.0984 Validation Accuracy: 0.613200\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     0.0339 Validation Accuracy: 0.624000\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     0.0469 Validation Accuracy: 0.620400\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     0.0942 Validation Accuracy: 0.615800\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.622200\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     0.0966 Validation Accuracy: 0.615600\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     0.0346 Validation Accuracy: 0.614000\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     0.0534 Validation Accuracy: 0.621400\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     0.0529 Validation Accuracy: 0.621600\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     0.0057 Validation Accuracy: 0.619800\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     0.1021 Validation Accuracy: 0.619400\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     0.0297 Validation Accuracy: 0.615400\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     0.0512 Validation Accuracy: 0.622400\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     0.0803 Validation Accuracy: 0.623000\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     0.0090 Validation Accuracy: 0.621000\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     0.1092 Validation Accuracy: 0.625600\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     0.0323 Validation Accuracy: 0.624000\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     0.0487 Validation Accuracy: 0.625000\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     0.0560 Validation Accuracy: 0.621800\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     0.0079 Validation Accuracy: 0.627000\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     0.1092 Validation Accuracy: 0.615800\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     0.0312 Validation Accuracy: 0.614800\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     0.0513 Validation Accuracy: 0.619000\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     0.0628 Validation Accuracy: 0.617200\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.618400\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     0.0529 Validation Accuracy: 0.616000\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     0.0325 Validation Accuracy: 0.618200\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     0.0494 Validation Accuracy: 0.630200\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     0.0923 Validation Accuracy: 0.620600\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     0.0126 Validation Accuracy: 0.616600\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     0.0874 Validation Accuracy: 0.615600\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     0.0304 Validation Accuracy: 0.611800\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     0.0477 Validation Accuracy: 0.619400\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     0.0955 Validation Accuracy: 0.622600\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     0.0088 Validation Accuracy: 0.617600\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     0.0651 Validation Accuracy: 0.612600\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     0.0353 Validation Accuracy: 0.611400\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     0.0476 Validation Accuracy: 0.619400\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     0.0923 Validation Accuracy: 0.614000\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.618000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     0.0836 Validation Accuracy: 0.614800\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     0.0303 Validation Accuracy: 0.605200\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     0.0474 Validation Accuracy: 0.621400\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     0.0903 Validation Accuracy: 0.618400\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     0.0078 Validation Accuracy: 0.621600\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     0.0869 Validation Accuracy: 0.617400\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     0.0324 Validation Accuracy: 0.619400\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     0.0472 Validation Accuracy: 0.622000\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     0.0562 Validation Accuracy: 0.618800\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     0.0060 Validation Accuracy: 0.617000\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     0.0676 Validation Accuracy: 0.623000\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     0.0299 Validation Accuracy: 0.617600\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     0.0500 Validation Accuracy: 0.618800\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     0.0506 Validation Accuracy: 0.622800\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     0.0040 Validation Accuracy: 0.618600\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     0.0601 Validation Accuracy: 0.612400\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     0.0335 Validation Accuracy: 0.612600\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     0.0516 Validation Accuracy: 0.620600\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     0.0543 Validation Accuracy: 0.616600\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.618600\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     0.0824 Validation Accuracy: 0.618000\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     0.0314 Validation Accuracy: 0.615800\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     0.0514 Validation Accuracy: 0.617000\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     0.0613 Validation Accuracy: 0.621600\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     0.0037 Validation Accuracy: 0.620800\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     0.0711 Validation Accuracy: 0.616000\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     0.0326 Validation Accuracy: 0.619000\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     0.0538 Validation Accuracy: 0.615800\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     0.0656 Validation Accuracy: 0.621400\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     0.0049 Validation Accuracy: 0.627200\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     0.0504 Validation Accuracy: 0.619200\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     0.0306 Validation Accuracy: 0.613000\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     0.0468 Validation Accuracy: 0.617600\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     0.0456 Validation Accuracy: 0.621400\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     0.0080 Validation Accuracy: 0.618800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     0.0766 Validation Accuracy: 0.612200\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     0.0296 Validation Accuracy: 0.614800\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     0.0481 Validation Accuracy: 0.619400\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     0.0454 Validation Accuracy: 0.619200\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     0.0057 Validation Accuracy: 0.615000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     0.0866 Validation Accuracy: 0.617400\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     0.0310 Validation Accuracy: 0.614200\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     0.0519 Validation Accuracy: 0.617200\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     0.0483 Validation Accuracy: 0.623600\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.618200\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     0.0544 Validation Accuracy: 0.614400\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     0.0313 Validation Accuracy: 0.614400\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     0.0474 Validation Accuracy: 0.621000\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     0.0908 Validation Accuracy: 0.622200\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     0.0029 Validation Accuracy: 0.623600\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     0.0639 Validation Accuracy: 0.611600\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     0.0305 Validation Accuracy: 0.614000\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     0.0482 Validation Accuracy: 0.620600\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     0.0814 Validation Accuracy: 0.618600\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.629800\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     0.0588 Validation Accuracy: 0.624600\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     0.0308 Validation Accuracy: 0.617200\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     0.0496 Validation Accuracy: 0.619800\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     0.0901 Validation Accuracy: 0.622400\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.615400\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.0682 Validation Accuracy: 0.613800\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     0.0337 Validation Accuracy: 0.621600\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     0.0483 Validation Accuracy: 0.623400\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     0.0884 Validation Accuracy: 0.614600\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.620000\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.0642 Validation Accuracy: 0.621200\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     0.0308 Validation Accuracy: 0.615600\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     0.0475 Validation Accuracy: 0.619600\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     0.0707 Validation Accuracy: 0.614800\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     0.0073 Validation Accuracy: 0.614600\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.0490 Validation Accuracy: 0.608400\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     0.0159 Validation Accuracy: 0.614600\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     0.0470 Validation Accuracy: 0.617800\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     0.0965 Validation Accuracy: 0.618000\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.623600\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.0628 Validation Accuracy: 0.616600\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     0.0122 Validation Accuracy: 0.612000\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     0.0603 Validation Accuracy: 0.613200\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     0.0976 Validation Accuracy: 0.616200\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     0.0065 Validation Accuracy: 0.622600\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     0.0752 Validation Accuracy: 0.615400\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     0.0116 Validation Accuracy: 0.620800\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     0.0470 Validation Accuracy: 0.622800\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     0.0460 Validation Accuracy: 0.616600\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     0.0057 Validation Accuracy: 0.625000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.0558 Validation Accuracy: 0.617800\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     0.0091 Validation Accuracy: 0.609800\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     0.0500 Validation Accuracy: 0.619600\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     0.0485 Validation Accuracy: 0.614800\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.619000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.0488 Validation Accuracy: 0.615200\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     0.0101 Validation Accuracy: 0.618400\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     0.0455 Validation Accuracy: 0.622800\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     0.1047 Validation Accuracy: 0.615600\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     0.0059 Validation Accuracy: 0.628400\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.0609 Validation Accuracy: 0.620000\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     0.0150 Validation Accuracy: 0.616000\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     0.0471 Validation Accuracy: 0.624200\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     0.0578 Validation Accuracy: 0.624800\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     0.0060 Validation Accuracy: 0.626000\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     0.0453 Validation Accuracy: 0.617800\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     0.0091 Validation Accuracy: 0.621600\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     0.0490 Validation Accuracy: 0.618800\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     0.0650 Validation Accuracy: 0.618600\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     0.0115 Validation Accuracy: 0.616000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     0.0360 Validation Accuracy: 0.610200\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     0.0065 Validation Accuracy: 0.610600\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     0.0492 Validation Accuracy: 0.614600\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     0.0521 Validation Accuracy: 0.619400\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.617800\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     0.0556 Validation Accuracy: 0.620000\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     0.0098 Validation Accuracy: 0.608600\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.0453 Validation Accuracy: 0.618400\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     0.0660 Validation Accuracy: 0.618600\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     0.0054 Validation Accuracy: 0.613400\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     0.0390 Validation Accuracy: 0.614800\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     0.0270 Validation Accuracy: 0.612200\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.0468 Validation Accuracy: 0.622200\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     0.0939 Validation Accuracy: 0.622800\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     0.0057 Validation Accuracy: 0.616800\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     0.0601 Validation Accuracy: 0.617600\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     0.0241 Validation Accuracy: 0.620200\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.0497 Validation Accuracy: 0.623800\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     0.0994 Validation Accuracy: 0.616600\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     0.0047 Validation Accuracy: 0.619000\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     0.0260 Validation Accuracy: 0.620600\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     0.0151 Validation Accuracy: 0.611400\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.0457 Validation Accuracy: 0.625400\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     0.0843 Validation Accuracy: 0.614400\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     0.0073 Validation Accuracy: 0.620200\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.0371 Validation Accuracy: 0.615600\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     0.0082 Validation Accuracy: 0.611400\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.0448 Validation Accuracy: 0.614400\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     0.0832 Validation Accuracy: 0.617600\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     0.0063 Validation Accuracy: 0.622000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.0341 Validation Accuracy: 0.614200\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     0.0295 Validation Accuracy: 0.615800\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     0.0500 Validation Accuracy: 0.614800\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     0.0875 Validation Accuracy: 0.621400\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.619600\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.0306 Validation Accuracy: 0.613600\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     0.0139 Validation Accuracy: 0.610400\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.0496 Validation Accuracy: 0.620000\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     0.0847 Validation Accuracy: 0.620200\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     0.0066 Validation Accuracy: 0.620000\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.0334 Validation Accuracy: 0.609200\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     0.0102 Validation Accuracy: 0.614600\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.0484 Validation Accuracy: 0.622000\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     0.0856 Validation Accuracy: 0.618600\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.623800\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.0432 Validation Accuracy: 0.614600\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     0.0094 Validation Accuracy: 0.617000\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.0464 Validation Accuracy: 0.619200\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     0.0521 Validation Accuracy: 0.620400\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     0.0061 Validation Accuracy: 0.620600\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.0293 Validation Accuracy: 0.617800\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     0.0080 Validation Accuracy: 0.613000\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.0462 Validation Accuracy: 0.621000\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     0.0543 Validation Accuracy: 0.620200\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     0.0061 Validation Accuracy: 0.617600\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.0563 Validation Accuracy: 0.614600\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     0.0068 Validation Accuracy: 0.616400\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     0.0435 Validation Accuracy: 0.618200\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     0.0632 Validation Accuracy: 0.616000\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.615600\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.0256 Validation Accuracy: 0.623600\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     0.0078 Validation Accuracy: 0.617600\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.0452 Validation Accuracy: 0.619000\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     0.0906 Validation Accuracy: 0.621000\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     0.0065 Validation Accuracy: 0.616200\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.0311 Validation Accuracy: 0.615400\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     0.0187 Validation Accuracy: 0.623200\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.0470 Validation Accuracy: 0.622000\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     0.0725 Validation Accuracy: 0.613800\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.621800\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.0164 Validation Accuracy: 0.613200\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     0.0149 Validation Accuracy: 0.609800\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.0454 Validation Accuracy: 0.612400\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     0.0638 Validation Accuracy: 0.615000\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     0.0086 Validation Accuracy: 0.616200\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.0300 Validation Accuracy: 0.615200\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     0.0192 Validation Accuracy: 0.612000\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.0476 Validation Accuracy: 0.618200\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     0.0721 Validation Accuracy: 0.617600\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     0.0061 Validation Accuracy: 0.617600\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.0310 Validation Accuracy: 0.616000\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     0.0054 Validation Accuracy: 0.608800\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.0493 Validation Accuracy: 0.615600\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     0.0822 Validation Accuracy: 0.611000\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     0.0045 Validation Accuracy: 0.615800\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.0214 Validation Accuracy: 0.613800\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     0.0152 Validation Accuracy: 0.608600\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.0532 Validation Accuracy: 0.612000\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     0.0720 Validation Accuracy: 0.616000\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     0.0033 Validation Accuracy: 0.617400\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.0172 Validation Accuracy: 0.613800\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     0.0085 Validation Accuracy: 0.610200\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.0494 Validation Accuracy: 0.618000\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     0.0576 Validation Accuracy: 0.615400\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     0.0066 Validation Accuracy: 0.613600\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.0199 Validation Accuracy: 0.608600\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     0.0091 Validation Accuracy: 0.614600\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.0445 Validation Accuracy: 0.617000\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     0.0577 Validation Accuracy: 0.612800\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.616200\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.0139 Validation Accuracy: 0.613200\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.613200\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.0479 Validation Accuracy: 0.614400\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     0.0831 Validation Accuracy: 0.616400\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     0.0051 Validation Accuracy: 0.613200\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.0194 Validation Accuracy: 0.613400\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     0.0154 Validation Accuracy: 0.615600\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.0450 Validation Accuracy: 0.614600\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     0.0700 Validation Accuracy: 0.615400\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     0.0057 Validation Accuracy: 0.616000\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.0166 Validation Accuracy: 0.614600\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     0.0122 Validation Accuracy: 0.619400\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.0464 Validation Accuracy: 0.617600\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     0.0810 Validation Accuracy: 0.621600\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.616600\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.0260 Validation Accuracy: 0.622000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     0.0149 Validation Accuracy: 0.613800\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.0499 Validation Accuracy: 0.616800\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     0.0660 Validation Accuracy: 0.608600\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.616800\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.0162 Validation Accuracy: 0.612200\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     0.0267 Validation Accuracy: 0.612000\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.0497 Validation Accuracy: 0.614200\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     0.0452 Validation Accuracy: 0.615800\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.618400\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.0201 Validation Accuracy: 0.612000\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     0.0177 Validation Accuracy: 0.613400\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.0489 Validation Accuracy: 0.619000\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     0.0525 Validation Accuracy: 0.616200\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.612400\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.0127 Validation Accuracy: 0.617000\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     0.0147 Validation Accuracy: 0.617800\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.0469 Validation Accuracy: 0.618000\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     0.0365 Validation Accuracy: 0.615800\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     0.0093 Validation Accuracy: 0.621600\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.0305 Validation Accuracy: 0.612200\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     0.0140 Validation Accuracy: 0.613000\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.0452 Validation Accuracy: 0.613200\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     0.0542 Validation Accuracy: 0.614800\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     0.0064 Validation Accuracy: 0.616800\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.0244 Validation Accuracy: 0.622800\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     0.0097 Validation Accuracy: 0.619800\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.0444 Validation Accuracy: 0.618200\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     0.0259 Validation Accuracy: 0.608000\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     0.0050 Validation Accuracy: 0.619000\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.0173 Validation Accuracy: 0.614000\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     0.0077 Validation Accuracy: 0.612400\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.0469 Validation Accuracy: 0.615800\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     0.0611 Validation Accuracy: 0.615200\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     0.0075 Validation Accuracy: 0.621600\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     0.0210 Validation Accuracy: 0.616400\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     0.0103 Validation Accuracy: 0.618000\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.0464 Validation Accuracy: 0.618600\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     0.0594 Validation Accuracy: 0.611000\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.616800\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     0.0137 Validation Accuracy: 0.609000\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     0.0302 Validation Accuracy: 0.613600\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.0481 Validation Accuracy: 0.619000\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     0.0317 Validation Accuracy: 0.612400\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     0.0037 Validation Accuracy: 0.621800\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.0167 Validation Accuracy: 0.615600\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     0.0299 Validation Accuracy: 0.614400\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.0451 Validation Accuracy: 0.614000\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     0.0448 Validation Accuracy: 0.617000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.616400\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.0177 Validation Accuracy: 0.615000\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     0.0128 Validation Accuracy: 0.608200\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.0452 Validation Accuracy: 0.614600\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     0.0760 Validation Accuracy: 0.607000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.620200\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.0231 Validation Accuracy: 0.614600\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     0.0282 Validation Accuracy: 0.611600\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.617800\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     0.0734 Validation Accuracy: 0.610200\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     0.0049 Validation Accuracy: 0.618200\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.0268 Validation Accuracy: 0.619600\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     0.0196 Validation Accuracy: 0.616000\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.0452 Validation Accuracy: 0.617000\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     0.0674 Validation Accuracy: 0.617800\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     0.0035 Validation Accuracy: 0.616800\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.0291 Validation Accuracy: 0.615600\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     0.0286 Validation Accuracy: 0.620000\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.0445 Validation Accuracy: 0.618200\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     0.0847 Validation Accuracy: 0.621200\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     0.0049 Validation Accuracy: 0.619400\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.0146 Validation Accuracy: 0.621600\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     0.0157 Validation Accuracy: 0.614800\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.0486 Validation Accuracy: 0.620600\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     0.0769 Validation Accuracy: 0.609000\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.620600\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.0180 Validation Accuracy: 0.615200\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     0.0032 Validation Accuracy: 0.617000\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.0443 Validation Accuracy: 0.620600\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     0.0618 Validation Accuracy: 0.609200\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.609400\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.0286 Validation Accuracy: 0.606400\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     0.0076 Validation Accuracy: 0.614200\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.0497 Validation Accuracy: 0.616400\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     0.0877 Validation Accuracy: 0.614000\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     0.0038 Validation Accuracy: 0.618400\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.0209 Validation Accuracy: 0.621400\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     0.0076 Validation Accuracy: 0.614400\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.0449 Validation Accuracy: 0.620800\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     0.0684 Validation Accuracy: 0.621600\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     0.0045 Validation Accuracy: 0.617000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.0144 Validation Accuracy: 0.614400\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     0.0054 Validation Accuracy: 0.613600\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.0477 Validation Accuracy: 0.614800\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     0.0566 Validation Accuracy: 0.616000\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     0.0050 Validation Accuracy: 0.620200\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.0161 Validation Accuracy: 0.618200\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     0.0045 Validation Accuracy: 0.624200\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.0445 Validation Accuracy: 0.612200\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     0.0787 Validation Accuracy: 0.615000\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.622600\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.616000\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     0.0055 Validation Accuracy: 0.612400\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.0431 Validation Accuracy: 0.615200\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     0.0476 Validation Accuracy: 0.611200\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.620000\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.0181 Validation Accuracy: 0.615800\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     0.0029 Validation Accuracy: 0.621800\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.0439 Validation Accuracy: 0.620600\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     0.0409 Validation Accuracy: 0.616000\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.619600\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     0.0160 Validation Accuracy: 0.621200\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     0.0050 Validation Accuracy: 0.610000\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     0.0501 Validation Accuracy: 0.615400\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     0.0413 Validation Accuracy: 0.612400\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     0.0045 Validation Accuracy: 0.616000\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     0.0216 Validation Accuracy: 0.613400\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     0.0079 Validation Accuracy: 0.608200\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     0.0441 Validation Accuracy: 0.621000\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     0.0396 Validation Accuracy: 0.615200\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     0.0029 Validation Accuracy: 0.613600\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     0.0206 Validation Accuracy: 0.609800\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     0.0139 Validation Accuracy: 0.613600\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     0.0435 Validation Accuracy: 0.618800\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     0.0425 Validation Accuracy: 0.615600\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     0.0055 Validation Accuracy: 0.619600\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     0.0124 Validation Accuracy: 0.617000\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     0.0090 Validation Accuracy: 0.612200\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.617400\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     0.0404 Validation Accuracy: 0.616200\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.617800\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     0.0283 Validation Accuracy: 0.616600\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     0.0117 Validation Accuracy: 0.615000\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     0.0448 Validation Accuracy: 0.618200\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     0.0713 Validation Accuracy: 0.621800\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.607000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     0.0150 Validation Accuracy: 0.618400\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     0.0041 Validation Accuracy: 0.612000\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     0.0476 Validation Accuracy: 0.616400\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     0.0271 Validation Accuracy: 0.613800\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     0.0036 Validation Accuracy: 0.618200\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     0.0245 Validation Accuracy: 0.615800\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     0.0054 Validation Accuracy: 0.614600\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     0.0440 Validation Accuracy: 0.615000\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     0.0324 Validation Accuracy: 0.615000\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     0.0074 Validation Accuracy: 0.616800\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     0.0239 Validation Accuracy: 0.620000\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     0.0212 Validation Accuracy: 0.612000\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     0.0415 Validation Accuracy: 0.618600\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     0.0405 Validation Accuracy: 0.619200\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     0.0054 Validation Accuracy: 0.624600\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     0.0259 Validation Accuracy: 0.615400\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     0.0069 Validation Accuracy: 0.606600\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.619400\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     0.0360 Validation Accuracy: 0.620800\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.616000\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     0.0445 Validation Accuracy: 0.611800\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     0.0081 Validation Accuracy: 0.613400\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.618000\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     0.0534 Validation Accuracy: 0.611200\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     0.0046 Validation Accuracy: 0.617200\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     0.0197 Validation Accuracy: 0.614200\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     0.0197 Validation Accuracy: 0.616600\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.0444 Validation Accuracy: 0.617200\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     0.0303 Validation Accuracy: 0.613000\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.617200\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     0.0224 Validation Accuracy: 0.608600\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     0.0075 Validation Accuracy: 0.617200\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.0454 Validation Accuracy: 0.622200\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     0.0236 Validation Accuracy: 0.619000\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.615400\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     0.0144 Validation Accuracy: 0.619800\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     0.0085 Validation Accuracy: 0.618400\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.0436 Validation Accuracy: 0.620800\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     0.0547 Validation Accuracy: 0.616800\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.609600\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.619200\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     0.0056 Validation Accuracy: 0.615000\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.0429 Validation Accuracy: 0.616600\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     0.0325 Validation Accuracy: 0.621000\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     0.0041 Validation Accuracy: 0.622000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     0.0168 Validation Accuracy: 0.607600\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     0.0037 Validation Accuracy: 0.622800\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.0453 Validation Accuracy: 0.622400\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     0.0290 Validation Accuracy: 0.616800\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     0.0021 Validation Accuracy: 0.619800\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     0.0133 Validation Accuracy: 0.616800\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     0.0096 Validation Accuracy: 0.615400\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.621200\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     0.0307 Validation Accuracy: 0.616200\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.618600\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     0.0143 Validation Accuracy: 0.618200\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     0.0107 Validation Accuracy: 0.621000\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.618200\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     0.0296 Validation Accuracy: 0.616000\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.621400\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.0216 Validation Accuracy: 0.616000\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     0.0201 Validation Accuracy: 0.611000\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.0442 Validation Accuracy: 0.618600\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     0.0564 Validation Accuracy: 0.618000\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.616600\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.0148 Validation Accuracy: 0.619600\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     0.0284 Validation Accuracy: 0.620400\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.0421 Validation Accuracy: 0.614000\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     0.0523 Validation Accuracy: 0.617600\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     0.0072 Validation Accuracy: 0.618800\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.0184 Validation Accuracy: 0.614000\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     0.0154 Validation Accuracy: 0.613600\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.0447 Validation Accuracy: 0.616400\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     0.0343 Validation Accuracy: 0.616200\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.616400\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.0155 Validation Accuracy: 0.617800\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     0.0047 Validation Accuracy: 0.620400\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.0417 Validation Accuracy: 0.626400\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     0.0532 Validation Accuracy: 0.618000\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     0.0070 Validation Accuracy: 0.617800\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.0186 Validation Accuracy: 0.613800\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     0.0047 Validation Accuracy: 0.614200\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.0429 Validation Accuracy: 0.620200\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     0.0698 Validation Accuracy: 0.615200\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     0.0030 Validation Accuracy: 0.617200\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.0124 Validation Accuracy: 0.609800\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     0.0026 Validation Accuracy: 0.618400\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.0484 Validation Accuracy: 0.615800\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     0.0378 Validation Accuracy: 0.616000\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     0.0030 Validation Accuracy: 0.614800\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.613600\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     0.0055 Validation Accuracy: 0.618400\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.0455 Validation Accuracy: 0.611400\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     0.0239 Validation Accuracy: 0.610200\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     0.0055 Validation Accuracy: 0.617400\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.0218 Validation Accuracy: 0.616400\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     0.0066 Validation Accuracy: 0.610200\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.0419 Validation Accuracy: 0.619200\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     0.0353 Validation Accuracy: 0.605400\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.615200\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.0136 Validation Accuracy: 0.613800\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.616000\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.0418 Validation Accuracy: 0.615800\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     0.0287 Validation Accuracy: 0.607600\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     0.0015 Validation Accuracy: 0.613600\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.0175 Validation Accuracy: 0.619600\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.612600\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.0422 Validation Accuracy: 0.625000\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     0.0320 Validation Accuracy: 0.613600\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     0.0047 Validation Accuracy: 0.614600\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.0123 Validation Accuracy: 0.614800\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     0.0038 Validation Accuracy: 0.614000\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.0406 Validation Accuracy: 0.618400\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     0.0308 Validation Accuracy: 0.617600\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.617600\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.0183 Validation Accuracy: 0.610600\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     0.0026 Validation Accuracy: 0.616800\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.0422 Validation Accuracy: 0.615200\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     0.0352 Validation Accuracy: 0.612600\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     0.0109 Validation Accuracy: 0.618800\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.0198 Validation Accuracy: 0.620200\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     0.0048 Validation Accuracy: 0.617600\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.0420 Validation Accuracy: 0.621400\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     0.0393 Validation Accuracy: 0.619600\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     0.0031 Validation Accuracy: 0.618200\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.0216 Validation Accuracy: 0.610400\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     0.0048 Validation Accuracy: 0.612800\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.0409 Validation Accuracy: 0.616800\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     0.0198 Validation Accuracy: 0.608800\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.617200\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.0125 Validation Accuracy: 0.606400\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.615600\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.0411 Validation Accuracy: 0.615800\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     0.0294 Validation Accuracy: 0.620400\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     0.0044 Validation Accuracy: 0.617200\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.0155 Validation Accuracy: 0.609600\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     0.0072 Validation Accuracy: 0.616200\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.0428 Validation Accuracy: 0.617000\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     0.0239 Validation Accuracy: 0.616800\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     0.0029 Validation Accuracy: 0.611400\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.0134 Validation Accuracy: 0.608600\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     0.0108 Validation Accuracy: 0.621000\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.0410 Validation Accuracy: 0.616200\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     0.0253 Validation Accuracy: 0.611200\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     0.0056 Validation Accuracy: 0.618800\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.0186 Validation Accuracy: 0.608200\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     0.0029 Validation Accuracy: 0.618200\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.0414 Validation Accuracy: 0.616800\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     0.0238 Validation Accuracy: 0.615400\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     0.0040 Validation Accuracy: 0.619800\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.0272 Validation Accuracy: 0.617400\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     0.0022 Validation Accuracy: 0.615400\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.0429 Validation Accuracy: 0.618200\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     0.0233 Validation Accuracy: 0.617000\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.616800\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.0099 Validation Accuracy: 0.609000\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.614400\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.616600\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     0.0390 Validation Accuracy: 0.612800\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     0.0035 Validation Accuracy: 0.622400\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.608200\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     0.0027 Validation Accuracy: 0.611200\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.0427 Validation Accuracy: 0.618200\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     0.0367 Validation Accuracy: 0.620600\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     0.0077 Validation Accuracy: 0.620000\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.611800\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     0.0069 Validation Accuracy: 0.620200\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.0416 Validation Accuracy: 0.619200\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     0.0270 Validation Accuracy: 0.612800\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     0.0067 Validation Accuracy: 0.616000\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.0172 Validation Accuracy: 0.614600\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     0.0052 Validation Accuracy: 0.615800\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.0409 Validation Accuracy: 0.619600\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     0.0280 Validation Accuracy: 0.615400\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     0.0014 Validation Accuracy: 0.612400\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.0126 Validation Accuracy: 0.620800\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.616400\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.0422 Validation Accuracy: 0.622000\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     0.0295 Validation Accuracy: 0.619400\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     0.0016 Validation Accuracy: 0.619200\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.0148 Validation Accuracy: 0.614600\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     0.0027 Validation Accuracy: 0.616800\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.0411 Validation Accuracy: 0.614600\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     0.0222 Validation Accuracy: 0.611200\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     0.0065 Validation Accuracy: 0.615400\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.0155 Validation Accuracy: 0.610600\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.619800\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.0410 Validation Accuracy: 0.620000\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     0.0165 Validation Accuracy: 0.617000\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.617400\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.0167 Validation Accuracy: 0.615400\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     0.0024 Validation Accuracy: 0.618800\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.620800\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     0.0374 Validation Accuracy: 0.627000\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.622800\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.0168 Validation Accuracy: 0.612600\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     0.0032 Validation Accuracy: 0.622200\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.617000\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     0.0234 Validation Accuracy: 0.618400\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.620600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.0185 Validation Accuracy: 0.615200\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     0.0027 Validation Accuracy: 0.617200\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.0412 Validation Accuracy: 0.621600\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     0.0253 Validation Accuracy: 0.609000\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.617000\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.0219 Validation Accuracy: 0.613600\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     0.0030 Validation Accuracy: 0.615000\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.0415 Validation Accuracy: 0.621000\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     0.0182 Validation Accuracy: 0.614800\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     0.0038 Validation Accuracy: 0.614600\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.618600\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     0.0007 Validation Accuracy: 0.617000\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.0439 Validation Accuracy: 0.621200\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     0.0289 Validation Accuracy: 0.620200\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     0.0079 Validation Accuracy: 0.613800\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.0139 Validation Accuracy: 0.620000\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     0.0037 Validation Accuracy: 0.614800\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.618600\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     0.0277 Validation Accuracy: 0.616000\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     0.0050 Validation Accuracy: 0.613000\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.0182 Validation Accuracy: 0.612000\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     0.0039 Validation Accuracy: 0.620600\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.0443 Validation Accuracy: 0.622600\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     0.0296 Validation Accuracy: 0.611000\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.620200\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.0142 Validation Accuracy: 0.613200\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     0.0118 Validation Accuracy: 0.621800\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.0421 Validation Accuracy: 0.615600\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     0.0255 Validation Accuracy: 0.617600\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.615800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.0170 Validation Accuracy: 0.611200\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     0.0047 Validation Accuracy: 0.619600\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.0438 Validation Accuracy: 0.614600\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     0.0151 Validation Accuracy: 0.614200\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     0.0053 Validation Accuracy: 0.616400\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.0159 Validation Accuracy: 0.617000\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.609000\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.0409 Validation Accuracy: 0.621400\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     0.0266 Validation Accuracy: 0.611600\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     0.0065 Validation Accuracy: 0.615400\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.0111 Validation Accuracy: 0.613000\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     0.0022 Validation Accuracy: 0.616600\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.0423 Validation Accuracy: 0.618600\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     0.0206 Validation Accuracy: 0.614600\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     0.0018 Validation Accuracy: 0.618200\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.0167 Validation Accuracy: 0.614000\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     0.0145 Validation Accuracy: 0.615000\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.0413 Validation Accuracy: 0.613200\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     0.0181 Validation Accuracy: 0.619200\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     0.0069 Validation Accuracy: 0.620400\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.0295 Validation Accuracy: 0.618400\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     0.0089 Validation Accuracy: 0.615800\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.0404 Validation Accuracy: 0.620800\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     0.0203 Validation Accuracy: 0.617400\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     0.0038 Validation Accuracy: 0.614400\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.0163 Validation Accuracy: 0.614400\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     0.0015 Validation Accuracy: 0.613800\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.0437 Validation Accuracy: 0.623000\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     0.0202 Validation Accuracy: 0.617200\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     0.0041 Validation Accuracy: 0.612000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.0125 Validation Accuracy: 0.617400\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.619000\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.0430 Validation Accuracy: 0.620400\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     0.0216 Validation Accuracy: 0.613600\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     0.0023 Validation Accuracy: 0.619800\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.0173 Validation Accuracy: 0.615200\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     0.0027 Validation Accuracy: 0.617800\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.0452 Validation Accuracy: 0.614600\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     0.0150 Validation Accuracy: 0.618000\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     0.0073 Validation Accuracy: 0.613400\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.0126 Validation Accuracy: 0.617800\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     0.0053 Validation Accuracy: 0.618200\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.620400\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     0.0205 Validation Accuracy: 0.619000\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.621200\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.0182 Validation Accuracy: 0.614400\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     0.0049 Validation Accuracy: 0.615000\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.0424 Validation Accuracy: 0.618600\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     0.0283 Validation Accuracy: 0.620400\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.620400\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.0137 Validation Accuracy: 0.615000\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     0.0034 Validation Accuracy: 0.620000\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.0420 Validation Accuracy: 0.614000\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     0.0494 Validation Accuracy: 0.618200\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     0.0028 Validation Accuracy: 0.615000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.0114 Validation Accuracy: 0.611600\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     0.0110 Validation Accuracy: 0.618000\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.0406 Validation Accuracy: 0.614200\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     0.0296 Validation Accuracy: 0.617400\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     0.0048 Validation Accuracy: 0.610000\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.0135 Validation Accuracy: 0.616400\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     0.0019 Validation Accuracy: 0.623000\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.0416 Validation Accuracy: 0.620000\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     0.0236 Validation Accuracy: 0.619000\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     0.0030 Validation Accuracy: 0.622800\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.0099 Validation Accuracy: 0.616400\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     0.0043 Validation Accuracy: 0.620600\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.0408 Validation Accuracy: 0.610800\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     0.0265 Validation Accuracy: 0.616600\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     0.0033 Validation Accuracy: 0.613800\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.0092 Validation Accuracy: 0.613200\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     0.0045 Validation Accuracy: 0.615200\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.0403 Validation Accuracy: 0.617000\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     0.0229 Validation Accuracy: 0.617600\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     0.0042 Validation Accuracy: 0.621600\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.0143 Validation Accuracy: 0.612600\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     0.0068 Validation Accuracy: 0.617600\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.0416 Validation Accuracy: 0.616600\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     0.0226 Validation Accuracy: 0.613800\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     0.0027 Validation Accuracy: 0.620000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.0150 Validation Accuracy: 0.614000\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.617800\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.0394 Validation Accuracy: 0.619600\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     0.0173 Validation Accuracy: 0.616000\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     0.0036 Validation Accuracy: 0.621000\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.0147 Validation Accuracy: 0.609000\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     0.0022 Validation Accuracy: 0.614600\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.0413 Validation Accuracy: 0.614800\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     0.0236 Validation Accuracy: 0.611600\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     0.0037 Validation Accuracy: 0.614600\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.0114 Validation Accuracy: 0.609800\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.612200\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.0407 Validation Accuracy: 0.617000\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     0.0320 Validation Accuracy: 0.610400\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.618200\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.0147 Validation Accuracy: 0.608600\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     0.0028 Validation Accuracy: 0.610400\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.0404 Validation Accuracy: 0.615200\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     0.0233 Validation Accuracy: 0.620400\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     0.0058 Validation Accuracy: 0.613600\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.0112 Validation Accuracy: 0.617000\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     0.0064 Validation Accuracy: 0.612600\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.0400 Validation Accuracy: 0.610800\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     0.0191 Validation Accuracy: 0.621000\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     0.0052 Validation Accuracy: 0.614200\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.0133 Validation Accuracy: 0.612800\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     0.0097 Validation Accuracy: 0.614000\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.0410 Validation Accuracy: 0.616200\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     0.0199 Validation Accuracy: 0.614000\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     0.0029 Validation Accuracy: 0.615800\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.0158 Validation Accuracy: 0.613800\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     0.0159 Validation Accuracy: 0.613200\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.0416 Validation Accuracy: 0.613000\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     0.0233 Validation Accuracy: 0.612600\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     0.0047 Validation Accuracy: 0.614000\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.0117 Validation Accuracy: 0.612000\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     0.0095 Validation Accuracy: 0.610600\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.0410 Validation Accuracy: 0.616400\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     0.0264 Validation Accuracy: 0.609800\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.618200\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.0176 Validation Accuracy: 0.613400\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     0.0064 Validation Accuracy: 0.610000\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.0407 Validation Accuracy: 0.616400\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     0.0301 Validation Accuracy: 0.618400\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     0.0036 Validation Accuracy: 0.623000\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.0169 Validation Accuracy: 0.621800\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.616000\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.0400 Validation Accuracy: 0.616200\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     0.0197 Validation Accuracy: 0.617000\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     0.0020 Validation Accuracy: 0.621400\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.0138 Validation Accuracy: 0.616200\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     0.0057 Validation Accuracy: 0.617600\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.0414 Validation Accuracy: 0.620400\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     0.0183 Validation Accuracy: 0.617000\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     0.0173 Validation Accuracy: 0.616200\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.0241 Validation Accuracy: 0.616400\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     0.0034 Validation Accuracy: 0.602000\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.0438 Validation Accuracy: 0.612200\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     0.0167 Validation Accuracy: 0.607400\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     0.0054 Validation Accuracy: 0.617000\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.0143 Validation Accuracy: 0.615800\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     0.0035 Validation Accuracy: 0.611600\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.0397 Validation Accuracy: 0.621400\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     0.0211 Validation Accuracy: 0.614800\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     0.0040 Validation Accuracy: 0.614200\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.0128 Validation Accuracy: 0.610400\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     0.0062 Validation Accuracy: 0.625200\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.0398 Validation Accuracy: 0.616600\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     0.0220 Validation Accuracy: 0.615600\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     0.0020 Validation Accuracy: 0.619800\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.0112 Validation Accuracy: 0.617000\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     0.0028 Validation Accuracy: 0.612800\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.614600\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     0.0244 Validation Accuracy: 0.618000\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     0.0011 Validation Accuracy: 0.620400\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.0103 Validation Accuracy: 0.616200\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     0.0035 Validation Accuracy: 0.620800\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.617600\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     0.0147 Validation Accuracy: 0.616200\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     0.0077 Validation Accuracy: 0.612200\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.0129 Validation Accuracy: 0.615600\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     0.0033 Validation Accuracy: 0.616000\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.0406 Validation Accuracy: 0.619600\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     0.0283 Validation Accuracy: 0.616800\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     0.0033 Validation Accuracy: 0.616600\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.0185 Validation Accuracy: 0.615200\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     0.0035 Validation Accuracy: 0.615000\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.617800\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     0.0232 Validation Accuracy: 0.616600\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     0.0027 Validation Accuracy: 0.623200\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.0199 Validation Accuracy: 0.612200\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     0.0026 Validation Accuracy: 0.612400\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.0403 Validation Accuracy: 0.623000\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     0.0207 Validation Accuracy: 0.617000\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     0.0024 Validation Accuracy: 0.620200\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.0135 Validation Accuracy: 0.612800\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     0.0026 Validation Accuracy: 0.617200\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.0426 Validation Accuracy: 0.618000\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     0.0235 Validation Accuracy: 0.618200\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     0.0018 Validation Accuracy: 0.618200\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.0140 Validation Accuracy: 0.625800\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     0.0018 Validation Accuracy: 0.621200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.0401 Validation Accuracy: 0.621800\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     0.0246 Validation Accuracy: 0.614400\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     0.0031 Validation Accuracy: 0.613400\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.0100 Validation Accuracy: 0.610000\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     0.0066 Validation Accuracy: 0.609200\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.0396 Validation Accuracy: 0.615600\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     0.0196 Validation Accuracy: 0.612400\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.613200\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.0158 Validation Accuracy: 0.614400\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     0.0013 Validation Accuracy: 0.614400\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.0398 Validation Accuracy: 0.619200\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     0.0236 Validation Accuracy: 0.613800\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     0.0077 Validation Accuracy: 0.616800\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.0109 Validation Accuracy: 0.610800\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     0.0035 Validation Accuracy: 0.609000\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.0411 Validation Accuracy: 0.611200\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     0.0195 Validation Accuracy: 0.613800\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.615800\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.0053 Validation Accuracy: 0.612800\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     0.0011 Validation Accuracy: 0.615200\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.0409 Validation Accuracy: 0.616600\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     0.0257 Validation Accuracy: 0.617200\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     0.0025 Validation Accuracy: 0.607800\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.0088 Validation Accuracy: 0.611000\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.613400\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.0394 Validation Accuracy: 0.615600\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     0.0189 Validation Accuracy: 0.608400\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     0.0034 Validation Accuracy: 0.608800\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.0043 Validation Accuracy: 0.605600\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     0.0018 Validation Accuracy: 0.603400\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.0407 Validation Accuracy: 0.607600\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     0.0263 Validation Accuracy: 0.610000\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     0.0030 Validation Accuracy: 0.609000\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.0145 Validation Accuracy: 0.610800\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     0.0034 Validation Accuracy: 0.612600\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.0430 Validation Accuracy: 0.616400\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     0.0252 Validation Accuracy: 0.616000\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     0.0014 Validation Accuracy: 0.611000\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.0085 Validation Accuracy: 0.613000\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     0.0044 Validation Accuracy: 0.617200\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.0401 Validation Accuracy: 0.616200\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     0.0241 Validation Accuracy: 0.614800\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     0.0081 Validation Accuracy: 0.616800\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.0077 Validation Accuracy: 0.612400\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     0.0025 Validation Accuracy: 0.606600\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.0397 Validation Accuracy: 0.610600\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     0.0295 Validation Accuracy: 0.616000\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     0.0016 Validation Accuracy: 0.614200\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.0203 Validation Accuracy: 0.619600\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     0.0018 Validation Accuracy: 0.614000\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.0396 Validation Accuracy: 0.617800\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     0.0160 Validation Accuracy: 0.607000\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     0.0062 Validation Accuracy: 0.614400\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.0093 Validation Accuracy: 0.614200\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     0.0010 Validation Accuracy: 0.617600\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.0406 Validation Accuracy: 0.617200\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     0.0187 Validation Accuracy: 0.613600\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     0.0010 Validation Accuracy: 0.616400\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.0106 Validation Accuracy: 0.615800\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     0.0047 Validation Accuracy: 0.616400\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.0403 Validation Accuracy: 0.617400\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     0.0224 Validation Accuracy: 0.600200\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.612600\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.0098 Validation Accuracy: 0.611400\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     0.0012 Validation Accuracy: 0.609800\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.0398 Validation Accuracy: 0.611600\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     0.0214 Validation Accuracy: 0.608200\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     0.0014 Validation Accuracy: 0.618000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.0118 Validation Accuracy: 0.614800\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     0.0037 Validation Accuracy: 0.619600\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.0396 Validation Accuracy: 0.615600\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     0.0295 Validation Accuracy: 0.614200\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     0.0018 Validation Accuracy: 0.620000\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.0075 Validation Accuracy: 0.613200\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     0.0006 Validation Accuracy: 0.616000\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.0424 Validation Accuracy: 0.616400\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     0.0223 Validation Accuracy: 0.607800\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     0.0019 Validation Accuracy: 0.612200\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.0122 Validation Accuracy: 0.609200\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     0.0031 Validation Accuracy: 0.609000\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.0401 Validation Accuracy: 0.619800\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     0.0219 Validation Accuracy: 0.610800\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     0.0026 Validation Accuracy: 0.614600\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.0073 Validation Accuracy: 0.616400\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     0.0009 Validation Accuracy: 0.610400\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.618000\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     0.0214 Validation Accuracy: 0.612200\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.612200\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.0098 Validation Accuracy: 0.614000\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     0.0015 Validation Accuracy: 0.619800\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.0394 Validation Accuracy: 0.624000\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     0.0228 Validation Accuracy: 0.610400\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     0.0012 Validation Accuracy: 0.611000\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.0069 Validation Accuracy: 0.612400\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     0.0030 Validation Accuracy: 0.612400\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.0398 Validation Accuracy: 0.612400\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     0.0195 Validation Accuracy: 0.611600\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     0.0020 Validation Accuracy: 0.609400\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.0081 Validation Accuracy: 0.614600\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     0.0001 Validation Accuracy: 0.609000\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.0404 Validation Accuracy: 0.612000\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     0.0149 Validation Accuracy: 0.609000\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     0.0043 Validation Accuracy: 0.614000\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.0053 Validation Accuracy: 0.607800\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     0.0002 Validation Accuracy: 0.619400\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.0395 Validation Accuracy: 0.622400\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     0.0173 Validation Accuracy: 0.613200\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     0.0045 Validation Accuracy: 0.613800\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.0145 Validation Accuracy: 0.614400\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     0.0003 Validation Accuracy: 0.618200\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.0402 Validation Accuracy: 0.618400\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     0.0288 Validation Accuracy: 0.618400\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     0.0055 Validation Accuracy: 0.605800\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.0088 Validation Accuracy: 0.618400\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     0.0002 Validation Accuracy: 0.609400\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.0408 Validation Accuracy: 0.612800\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     0.0184 Validation Accuracy: 0.613400\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     0.0032 Validation Accuracy: 0.615800\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.0065 Validation Accuracy: 0.613200\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     0.0007 Validation Accuracy: 0.610400\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.0401 Validation Accuracy: 0.619000\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     0.0235 Validation Accuracy: 0.614600\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     0.0022 Validation Accuracy: 0.613400\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.0215 Validation Accuracy: 0.607600\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     0.0012 Validation Accuracy: 0.616400\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.0405 Validation Accuracy: 0.615200\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     0.0278 Validation Accuracy: 0.611800\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     0.0023 Validation Accuracy: 0.614600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "logs_path = \"/tmp/cifar/2\"\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # create log writer object\n",
    "#     tf.summary.FileWriter\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, writer, \n",
    "                                     epoch * n_batches + batch_i)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6270767405063291\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njkVEREREIk2ORURERESi/w/XOY/5AG7iXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc174454a20>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
